{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyabsa in d:\\anaconda\\envs\\ml\\lib\\site-packages (1.16.16)\n",
      "Requirement already satisfied: spacy in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (3.3.1)\n",
      "Requirement already satisfied: boostaug>=2.2.3 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (2.2.4)\n",
      "Requirement already satisfied: seqeval in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (1.2.2)\n",
      "Requirement already satisfied: update-checker in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (0.18.0)\n",
      "Requirement already satisfied: gitpython in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (3.1.27)\n",
      "Requirement already satisfied: transformers>4.20.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (4.22.1)\n",
      "Requirement already satisfied: torch>1.0.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (1.12.1)\n",
      "Requirement already satisfied: autocuda>=0.11 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (0.11)\n",
      "Requirement already satisfied: gdown>=4.4.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (4.5.1)\n",
      "Requirement already satisfied: sentencepiece in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (0.1.97)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (2.8.6)\n",
      "Requirement already satisfied: findfile>=1.7.9.8 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (1.7.9.8)\n",
      "Requirement already satisfied: metric-visualizer>=0.5.5 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (0.5.10)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (4.3.0)\n",
      "Requirement already satisfied: pytorch-warmup in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (0.1.0)\n",
      "Requirement already satisfied: termcolor in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (1.1.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pyabsa) (4.64.0)\n",
      "Requirement already satisfied: six in d:\\anaconda\\envs\\ml\\lib\\site-packages (from gdown>=4.4.0->pyabsa) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from gdown>=4.4.0->pyabsa) (4.11.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\ml\\lib\\site-packages (from gdown>=4.4.0->pyabsa) (3.8.0)\n",
      "Requirement already satisfied: requests[socks] in d:\\anaconda\\envs\\ml\\lib\\site-packages (from gdown>=4.4.0->pyabsa) (2.28.1)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\envs\\ml\\lib\\site-packages (from metric-visualizer>=0.5.5->pyabsa) (1.9.1)\n",
      "Requirement already satisfied: tikzplotlib in d:\\anaconda\\envs\\ml\\lib\\site-packages (from metric-visualizer>=0.5.5->pyabsa) (0.10.1)\n",
      "Requirement already satisfied: natsort in d:\\anaconda\\envs\\ml\\lib\\site-packages (from metric-visualizer>=0.5.5->pyabsa) (8.2.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\envs\\ml\\lib\\site-packages (from metric-visualizer>=0.5.5->pyabsa) (1.23.1)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\envs\\ml\\lib\\site-packages (from metric-visualizer>=0.5.5->pyabsa) (3.6.0)\n",
      "Requirement already satisfied: tabulate in d:\\anaconda\\envs\\ml\\lib\\site-packages (from metric-visualizer>=0.5.5->pyabsa) (0.8.10)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from transformers>4.20.0->pyabsa) (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from transformers>4.20.0->pyabsa) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from transformers>4.20.0->pyabsa) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from transformers>4.20.0->pyabsa) (2022.9.13)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from transformers>4.20.0->pyabsa) (0.12.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\ml\\lib\\site-packages (from tqdm->pyabsa) (0.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from gitpython->pyabsa) (4.0.9)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from seqeval->pyabsa) (1.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (0.7.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (8.0.15)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (3.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (0.6.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (2.0.6)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (63.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (0.9.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (0.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (1.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (3.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (2.4.3)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from spacy->pyabsa) (3.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->pyabsa) (5.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from packaging>=20.0->transformers>4.20.0->pyabsa) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from pathy>=0.3.5->spacy->pyabsa) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->pyabsa) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->pyabsa) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->pyabsa) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->pyabsa) (2.0.4)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->pyabsa) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->pyabsa) (2.2.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy->pyabsa) (8.0.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from beautifulsoup4->gdown>=4.4.0->pyabsa) (2.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from jinja2->spacy->pyabsa) (2.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from matplotlib->metric-visualizer>=0.5.5->pyabsa) (4.37.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from matplotlib->metric-visualizer>=0.5.5->pyabsa) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from matplotlib->metric-visualizer>=0.5.5->pyabsa) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from matplotlib->metric-visualizer>=0.5.5->pyabsa) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from matplotlib->metric-visualizer>=0.5.5->pyabsa) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from matplotlib->metric-visualizer>=0.5.5->pyabsa) (1.0.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->pyabsa) (1.7.1)\n",
      "Requirement already satisfied: webcolors in d:\\anaconda\\envs\\ml\\lib\\site-packages (from tikzplotlib->metric-visualizer>=0.5.5->pyabsa) (1.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyabsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\envs\\ml\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This script could only be used to manage NVIDIA GPUs,but no GPU found in your device\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "from googletrans import Translator\n",
    "from transformers import pipeline\n",
    "import unicodedata\n",
    "#from pyabsa import available_checkpoints(from_local=False)\n",
    "from pyabsa import ATEPCCheckpointManager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET GREEK DATA FROM FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ξενος', 'ξενιζω ξενισ', 'ξενικος', 'βαρβαρος', 'βαρβαριζω βαρβαρισ', 'ελληνιζω', 'ελλην', 'ελληνικος', 'σολοικιζω', 'αρχαιζω', 'βαρβαριζω', 'βαρβαρικιον', 'βαρβαρικος', 'βαρβαρισμος', 'βαρβαριστι', 'βαρβαρογλωσσος', 'βαρβαροκτονος', 'βαρβαρος', 'βαρβαροστομια', 'βαρβαροτης', 'βαρβαροφωνεω', 'βαρβαροφωνος', 'βαρβαροω', 'βαρβαρωδης', 'σολοικος', 'σολοικια', 'σολοικιζω', 'σολοικιστης', 'σολοικισμος', 'σολοικιστης', 'σολοικοφανης', 'δημος', 'δημοποιητος', 'πολιτης', 'πολιτεια', 'αγριοφωνος', 'ελλην', 'γυνη', 'δουλαγωγεω', 'δουλαγωγια', 'δουλαγωγος', 'δουλαπατια', 'δουλαριον', 'δουλεια', 'δουλειος', 'δουλεκδουλος', 'δουλελευθερος', 'δουλεος', 'δουλευμα', 'δουλευσις', 'δουλευτεον', 'δουλευτος', 'δουλευτρια', 'δουλευω', 'δουλια', 'δουλιδιον', 'δουλικος', 'δουλιος', 'δουλις', 'δουλοβοτος', 'δουλογαμος', 'δουλογνωμων', 'δουλοδιδασκαλος', 'δουλοκοιτης', 'δουλοκρατεομαι', 'δουλοκρατια', 'δουλομαχια', 'δουλομικτης', 'δουλομιξια', 'δουλοποιεω', 'δουλοποιος', 'δουλοπονηρος', 'δουλοπρεπεια', 'δουλοπρεπης', 'δουλος', 'δουλοσυνη', 'δουλοσυνος', 'δουλοφανης', 'δουλοψυχος', 'δουλωσις', 'δουλωτικος', 'ρωμαιος', 'αλλοδαπος', 'αλλοδημια', 'αλλοδημος', 'αλλοεθνης', 'βαρβαρικος', 'βαρβαριστι,', 'βαρβαροκτονος', 'νοθος', 'εθνος', 'θηλυ', 'αρρεν', 'αλλοεθνης', 'γλωσσα', 'γλωττα', 'διαλεκτος', 'αττικος', 'αττικιζω', 'αττικιστι', 'αλλογλωσσια', 'αλλογλωσσος', 'αλλοδαπος', 'αλλοδημια', 'αιγυπτιος', 'τυραννος', 'περσης', 'χρωμα', 'νομος', 'εθος', 'γενος', 'ευγενεια', 'την μισω', 'τον αγαπω', 'δεν τον αγαπω', 'δεν τον μισω', 'ειναι βαρβαρος']\n"
     ]
    }
   ],
   "source": [
    "#encodeing must = utf8\n",
    "f= open('GreekList.txt', 'r',encoding='utf8') \n",
    "source = f.readlines()\n",
    "f.close()\n",
    "\n",
    "#remove /n from strings\n",
    "for index,item in enumerate(source): \n",
    "    source[index]=item.strip()\n",
    "\n",
    "def strip_accents_and_lowercase(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn').lower()\n",
    "def remove_hyphens(s):\n",
    "    return s.replace('-', '')\n",
    "    \n",
    "preprocessed=[None]*len(source)\n",
    "for index,item in enumerate(source): \n",
    "    preprocessed[index]=  remove_hyphens(strip_accents_and_lowercase(item))\n",
    "print(preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_1412\\3706790480.py:6: ResourceWarning: unclosed <ssl.SSLSocket fd=7660, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('192.168.254.65', 53095), raddr=('64.233.177.95', 443)>\n",
      "  for t in translated:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor t in translated:\\n    print(f'{t.origin} -> {t.text}')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#initialize class\n",
    "translator = Translator()\n",
    "#call googltranlate for each entry in lines\n",
    "translated = translator.translate(preprocessed,src='el',dest='en')\n",
    "translated_array=[]\n",
    "for t in translated:\n",
    "    translated_array.append(t.text)\n",
    "#print \n",
    "'''\n",
    "for t in translated:\n",
    "    print(f'{t.origin} -> {t.text}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ξενος  ->  foreign  ->    [{'label': 'Neutral', 'score': 0.6824287176132202}]\n",
      "\n",
      "ξενιζω ξενισ  ->  I miss you  ->    [{'label': 'Neutral', 'score': 0.5362865924835205}]\n",
      "\n",
      "ξενικος  ->  stranger  ->    [{'label': 'Neutral', 'score': 0.6344491243362427}]\n",
      "\n",
      "βαρβαρος  ->  barbarian  ->    [{'label': 'Neutral', 'score': 0.7430830597877502}]\n",
      "\n",
      "βαρβαριζω βαρβαρισ  ->  barbarize barbarize  ->    [{'label': 'Negative', 'score': 0.7282034754753113}]\n",
      "\n",
      "ελληνιζω  ->  Greekize  ->    [{'label': 'Neutral', 'score': 0.7068521976470947}]\n",
      "\n",
      "ελλην  ->  Greek  ->    [{'label': 'Neutral', 'score': 0.5975199341773987}]\n",
      "\n",
      "ελληνικος  ->  Greek  ->    [{'label': 'Neutral', 'score': 0.5975199341773987}]\n",
      "\n",
      "σολοικιζω  ->  I'm talking  ->    [{'label': 'Neutral', 'score': 0.7739629149436951}]\n",
      "\n",
      "αρχαιζω  ->  I am antiquing  ->    [{'label': 'Neutral', 'score': 0.6336979269981384}]\n",
      "\n",
      "βαρβαριζω  ->  barbarize  ->    [{'label': 'Neutral', 'score': 0.6367692947387695}]\n",
      "\n",
      "βαρβαρικιον  ->  barbaricion  ->    [{'label': 'Neutral', 'score': 0.7392947673797607}]\n",
      "\n",
      "βαρβαρικος  ->  barbaric  ->    [{'label': 'Neutral', 'score': 0.552249550819397}]\n",
      "\n",
      "βαρβαρισμος  ->  barbarism  ->    [{'label': 'Negative', 'score': 0.5131458640098572}]\n",
      "\n",
      "βαρβαριστι  ->  barbaric  ->    [{'label': 'Neutral', 'score': 0.552249550819397}]\n",
      "\n",
      "βαρβαρογλωσσος  ->  barbarian  ->    [{'label': 'Neutral', 'score': 0.7430830597877502}]\n",
      "\n",
      "βαρβαροκτονος  ->  barbaric killer  ->    [{'label': 'Negative', 'score': 0.8451356887817383}]\n",
      "\n",
      "βαρβαρος  ->  barbarian  ->    [{'label': 'Neutral', 'score': 0.7430830597877502}]\n",
      "\n",
      "βαρβαροστομια  ->  barbarostomies  ->    [{'label': 'Neutral', 'score': 0.7441659569740295}]\n",
      "\n",
      "βαρβαροτης  ->  brutality  ->    [{'label': 'Negative', 'score': 0.6947452425956726}]\n",
      "\n",
      "βαρβαροφωνεω  ->  I'm barbaric  ->    [{'label': 'Negative', 'score': 0.8546293377876282}]\n",
      "\n",
      "βαρβαροφωνος  ->  barbarian  ->    [{'label': 'Neutral', 'score': 0.7430830597877502}]\n",
      "\n",
      "βαρβαροω  ->  barbarian  ->    [{'label': 'Neutral', 'score': 0.7430830597877502}]\n",
      "\n",
      "βαρβαρωδης  ->  barbaric  ->    [{'label': 'Neutral', 'score': 0.552249550819397}]\n",
      "\n",
      "σολοικος  ->  ungrammatical  ->    [{'label': 'Negative', 'score': 0.48133885860443115}]\n",
      "\n",
      "σολοικια  ->  worms  ->    [{'label': 'Neutral', 'score': 0.6303571462631226}]\n",
      "\n",
      "σολοικιζω  ->  I'm talking  ->    [{'label': 'Neutral', 'score': 0.7739629149436951}]\n",
      "\n",
      "σολοικιστης  ->  colonist  ->    [{'label': 'Neutral', 'score': 0.555194079875946}]\n",
      "\n",
      "σολοικισμος  ->  colonization  ->    [{'label': 'Neutral', 'score': 0.6602259874343872}]\n",
      "\n",
      "σολοικιστης  ->  colonist  ->    [{'label': 'Neutral', 'score': 0.555194079875946}]\n",
      "\n",
      "σολοικοφανης  ->  soloicophanes  ->    [{'label': 'Neutral', 'score': 0.7005870938301086}]\n",
      "\n",
      "δημος  ->  municipality  ->    [{'label': 'Neutral', 'score': 0.759880781173706}]\n",
      "\n",
      "δημοποιητος  ->  published  ->    [{'label': 'Neutral', 'score': 0.6703561544418335}]\n",
      "\n",
      "πολιτης  ->  citizen  ->    [{'label': 'Neutral', 'score': 0.7029553651809692}]\n",
      "\n",
      "πολιτεια  ->  state  ->    [{'label': 'Neutral', 'score': 0.653049111366272}]\n",
      "\n",
      "αγριοφωνος  ->  wild-mouthed  ->    [{'label': 'Neutral', 'score': 0.5214740037918091}]\n",
      "\n",
      "ελλην  ->  Greek  ->    [{'label': 'Neutral', 'score': 0.5975199341773987}]\n",
      "\n",
      "γυνη  ->  woman  ->    [{'label': 'Neutral', 'score': 0.6428734660148621}]\n",
      "\n",
      "δουλαγωγεω  ->  i slave  ->    [{'label': 'Neutral', 'score': 0.6474059820175171}]\n",
      "\n",
      "δουλαγωγια  ->  slave girls  ->    [{'label': 'Negative', 'score': 0.6676355004310608}]\n",
      "\n",
      "δουλαγωγος  ->  slave driver  ->    [{'label': 'Negative', 'score': 0.7414072155952454}]\n",
      "\n",
      "δουλαπατια  ->  closets  ->    [{'label': 'Neutral', 'score': 0.714678943157196}]\n",
      "\n",
      "δουλαριον  ->  dollar  ->    [{'label': 'Neutral', 'score': 0.6216223239898682}]\n",
      "\n",
      "δουλεια  ->  work  ->    [{'label': 'Neutral', 'score': 0.6364321112632751}]\n",
      "\n",
      "δουλειος  ->  slave  ->    [{'label': 'Neutral', 'score': 0.4978238642215729}]\n",
      "\n",
      "δουλεκδουλος  ->  laborer  ->    [{'label': 'Neutral', 'score': 0.6919518709182739}]\n",
      "\n",
      "δουλελευθερος  ->  free slave  ->    [{'label': 'Neutral', 'score': 0.6808006167411804}]\n",
      "\n",
      "δουλεος  ->  slave  ->    [{'label': 'Neutral', 'score': 0.4978238642215729}]\n",
      "\n",
      "δουλευμα  ->  job  ->    [{'label': 'Neutral', 'score': 0.5981408357620239}]\n",
      "\n",
      "δουλευσις  ->  jobs  ->    [{'label': 'Neutral', 'score': 0.6284939646720886}]\n",
      "\n",
      "δουλευτεον  ->  I was working  ->    [{'label': 'Neutral', 'score': 0.7574771642684937}]\n",
      "\n",
      "δουλευτος  ->  worked  ->    [{'label': 'Neutral', 'score': 0.6727202534675598}]\n",
      "\n",
      "δουλευτρια  ->  maid  ->    [{'label': 'Neutral', 'score': 0.6720710396766663}]\n",
      "\n",
      "δουλευω  ->  I work  ->    [{'label': 'Neutral', 'score': 0.6495513916015625}]\n",
      "\n",
      "δουλια  ->  chores  ->    [{'label': 'Neutral', 'score': 0.6490976214408875}]\n",
      "\n",
      "δουλιδιον  ->  doulidion  ->    [{'label': 'Neutral', 'score': 0.7138749361038208}]\n",
      "\n",
      "δουλικος  ->  servile  ->    [{'label': 'Neutral', 'score': 0.5856009125709534}]\n",
      "\n",
      "δουλιος  ->  worker  ->    [{'label': 'Neutral', 'score': 0.668922483921051}]\n",
      "\n",
      "δουλις  ->  work  ->    [{'label': 'Neutral', 'score': 0.6364321112632751}]\n",
      "\n",
      "δουλοβοτος  ->  Servant  ->    [{'label': 'Neutral', 'score': 0.6737299561500549}]\n",
      "\n",
      "δουλογαμος  ->  servant  ->    [{'label': 'Neutral', 'score': 0.6351715922355652}]\n",
      "\n",
      "δουλογνωμων  ->  of slaves  ->    [{'label': 'Neutral', 'score': 0.5105410814285278}]\n",
      "\n",
      "δουλοδιδασκαλος  ->  slave teacher  ->    [{'label': 'Negative', 'score': 0.7428795695304871}]\n",
      "\n",
      "δουλοκοιτης  ->  servant  ->    [{'label': 'Neutral', 'score': 0.6351715922355652}]\n",
      "\n",
      "δουλοκρατεομαι  ->  I am enslaved  ->    [{'label': 'Negative', 'score': 0.7173168063163757}]\n",
      "\n",
      "δουλοκρατια  ->  slavery  ->    [{'label': 'Negative', 'score': 0.5292258858680725}]\n",
      "\n",
      "δουλομαχια  ->  slave battles  ->    [{'label': 'Negative', 'score': 0.5494652986526489}]\n",
      "\n",
      "δουλομικτης  ->  laborer  ->    [{'label': 'Neutral', 'score': 0.6919518709182739}]\n",
      "\n",
      "δουλομιξια  ->  labor mix  ->    [{'label': 'Neutral', 'score': 0.8109448552131653}]\n",
      "\n",
      "δουλοποιεω  ->  I enslave  ->    [{'label': 'Negative', 'score': 0.6560721397399902}]\n",
      "\n",
      "δουλοποιος  ->  slave worker  ->    [{'label': 'Negative', 'score': 0.6527373790740967}]\n",
      "\n",
      "δουλοπονηρος  ->  slavish  ->    [{'label': 'Neutral', 'score': 0.7565678358078003}]\n",
      "\n",
      "δουλοπρεπεια  ->  subservience  ->    [{'label': 'Neutral', 'score': 0.6313928961753845}]\n",
      "\n",
      "δουλοπρεπης  ->  servile  ->    [{'label': 'Neutral', 'score': 0.5856009125709534}]\n",
      "\n",
      "δουλος  ->  slave  ->    [{'label': 'Neutral', 'score': 0.4978238642215729}]\n",
      "\n",
      "δουλοσυνη  ->  servile  ->    [{'label': 'Neutral', 'score': 0.5856009125709534}]\n",
      "\n",
      "δουλοσυνος  ->  slavish  ->    [{'label': 'Neutral', 'score': 0.7565678358078003}]\n",
      "\n",
      "δουλοφανης  ->  slavish  ->    [{'label': 'Neutral', 'score': 0.7565678358078003}]\n",
      "\n",
      "δουλοψυχος  ->  servile  ->    [{'label': 'Neutral', 'score': 0.5856009125709534}]\n",
      "\n",
      "δουλωσις  ->  employment  ->    [{'label': 'Neutral', 'score': 0.5576841235160828}]\n",
      "\n",
      "δουλωτικος  ->  servile  ->    [{'label': 'Neutral', 'score': 0.5856009125709534}]\n",
      "\n",
      "ρωμαιος  ->  Roman  ->    [{'label': 'Neutral', 'score': 0.65412837266922}]\n",
      "\n",
      "αλλοδαπος  ->  foreign  ->    [{'label': 'Neutral', 'score': 0.6824287176132202}]\n",
      "\n",
      "αλλοδημια  ->  alienation  ->    [{'label': 'Neutral', 'score': 0.5839987993240356}]\n",
      "\n",
      "αλλοδημος  ->  foreigner  ->    [{'label': 'Neutral', 'score': 0.7452855110168457}]\n",
      "\n",
      "αλλοεθνης  ->  foreign  ->    [{'label': 'Neutral', 'score': 0.6824287176132202}]\n",
      "\n",
      "βαρβαρικος  ->  barbaric  ->    [{'label': 'Neutral', 'score': 0.552249550819397}]\n",
      "\n",
      "βαρβαριστι,  ->  barbaric,  ->    [{'label': 'Neutral', 'score': 0.6397427916526794}]\n",
      "\n",
      "βαρβαροκτονος  ->  barbaric killer  ->    [{'label': 'Negative', 'score': 0.8451356887817383}]\n",
      "\n",
      "νοθος  ->  illegitimate  ->    [{'label': 'Neutral', 'score': 0.5525532960891724}]\n",
      "\n",
      "εθνος  ->  nation  ->    [{'label': 'Neutral', 'score': 0.6089465022087097}]\n",
      "\n",
      "θηλυ  ->  female  ->    [{'label': 'Neutral', 'score': 0.6681264042854309}]\n",
      "\n",
      "αρρεν  ->  male  ->    [{'label': 'Neutral', 'score': 0.6526537537574768}]\n",
      "\n",
      "αλλοεθνης  ->  foreign  ->    [{'label': 'Neutral', 'score': 0.6824287176132202}]\n",
      "\n",
      "γλωσσα  ->  language  ->    [{'label': 'Neutral', 'score': 0.7173925638198853}]\n",
      "\n",
      "γλωττα  ->  tongue  ->    [{'label': 'Neutral', 'score': 0.7674258947372437}]\n",
      "\n",
      "διαλεκτος  ->  dialect  ->    [{'label': 'Neutral', 'score': 0.7736626267433167}]\n",
      "\n",
      "αττικος  ->  Attic  ->    [{'label': 'Neutral', 'score': 0.5780314207077026}]\n",
      "\n",
      "αττικιζω  ->  Atticize  ->    [{'label': 'Neutral', 'score': 0.6977302432060242}]\n",
      "\n",
      "αττικιστι  ->  Atticist  ->    [{'label': 'Neutral', 'score': 0.712135374546051}]\n",
      "\n",
      "αλλογλωσσια  ->  foreign languages  ->    [{'label': 'Neutral', 'score': 0.7670549750328064}]\n",
      "\n",
      "αλλογλωσσος  ->  foreign language  ->    [{'label': 'Neutral', 'score': 0.6780018210411072}]\n",
      "\n",
      "αλλοδαπος  ->  foreign  ->    [{'label': 'Neutral', 'score': 0.6824287176132202}]\n",
      "\n",
      "αλλοδημια  ->  alienation  ->    [{'label': 'Neutral', 'score': 0.5839987993240356}]\n",
      "\n",
      "αιγυπτιος  ->  Egyptian  ->    [{'label': 'Neutral', 'score': 0.7675987482070923}]\n",
      "\n",
      "τυραννος  ->  tyrant  ->    [{'label': 'Neutral', 'score': 0.6913937330245972}]\n",
      "\n",
      "περσης  ->  Persian  ->    [{'label': 'Neutral', 'score': 0.7633065581321716}]\n",
      "\n",
      "χρωμα  ->  colour  ->    [{'label': 'Neutral', 'score': 0.508502185344696}]\n",
      "\n",
      "νομος  ->  law  ->    [{'label': 'Neutral', 'score': 0.5902817845344543}]\n",
      "\n",
      "εθος  ->  custom  ->    [{'label': 'Neutral', 'score': 0.7101472616195679}]\n",
      "\n",
      "γενος  ->  genus  ->    [{'label': 'Neutral', 'score': 0.6324904561042786}]\n",
      "\n",
      "ευγενεια  ->  courtesy  ->    [{'label': 'Neutral', 'score': 0.6040051579475403}]\n",
      "\n",
      "την μισω  ->  I hate her  ->    [{'label': 'Negative', 'score': 0.861028254032135}]\n",
      "\n",
      "τον αγαπω  ->  I love him  ->    [{'label': 'Positive', 'score': 0.9311667084693909}]\n",
      "\n",
      "δεν τον αγαπω  ->  i don't love him  ->    [{'label': 'Negative', 'score': 0.7081413269042969}]\n",
      "\n",
      "δεν τον μισω  ->  I don't hate him  ->    [{'label': 'Neutral', 'score': 0.6229543685913086}]\n",
      "\n",
      "ειναι βαρβαρος  ->  he is barbaric  ->    [{'label': 'Negative', 'score': 0.8816542625427246}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model='cardiffnlp/twitter-roberta-base-sentiment-latest', \n",
    "tokenizer='cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "for t in translated:\n",
    "    print(f'{t.origin}  ->  {t.text}  ->    {sentiment_task(t.text)}\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASPECTBASED SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load aspect extractor from checkpoints\\ATEPC_ENGLISH_CHECKPOINT\n",
      "config: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc.config\n",
      "state_dict: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc.state_dict\n",
      "model: None\n",
      "tokenizer: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc.tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "d:\\ANACONDA\\envs\\ml\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config used in Training:\n",
      "ABSADatasetsVersion:None\t-->\tCalling Count:0\n",
      "IOB_label_to_index:{'B-ASP': 1, 'I-ASP': 2, 'O': 3, '[CLS]': 4, '[SEP]': 5}\t-->\tCalling Count:1\n",
      "MV:<metric_visualizer.metric_visualizer.MetricVisualizer object at 0x000001F5CFFD5130>\t-->\tCalling Count:0\n",
      "PyABSAVersion:1.15.7\t-->\tCalling Count:0\n",
      "SRD:3\t-->\tCalling Count:79070\n",
      "TorchVersion:1.10.0+cuda11.3\t-->\tCalling Count:0\n",
      "TransformersVersion:4.20.1\t-->\tCalling Count:0\n",
      "auto_device:True\t-->\tCalling Count:50569\n",
      "batch_size:16\t-->\tCalling Count:5\n",
      "cache_dataset:True\t-->\tCalling Count:1\n",
      "dataset_file:{'train': ['integrated_datasets/atepc_datasets/110.SemEval/113.laptop14/Laptops_Train.xml.seg.atepc', 'integrated_datasets/atepc_datasets/110.SemEval/114.restaurant14/Restaurants_Train.xml.seg.atepc', 'integrated_datasets/atepc_datasets/110.SemEval/116.restaurant16/restaurant_train.raw.atepc', 'integrated_datasets/atepc_datasets/101.ACL_Twitter/acl-14-short-data/train.raw.atepc', 'integrated_datasets/atepc_datasets/109.MAMS/train.xml.dat.atepc', 'integrated_datasets/atepc_datasets/117.Television/Television_Train.xml.seg.atepc', 'integrated_datasets/atepc_datasets/118.TShirt/Menstshirt_Train.xml.seg.atepc', 'integrated_datasets/atepc_datasets/119.Yelp/yelp.train.txt.atepc', 'integrated_datasets/atepc_datasets/121.MOOC_En/mooc-en.train.txt.atepc'], 'test': ['integrated_datasets/atepc_datasets/110.SemEval/113.laptop14/Laptops_Test_Gold.xml.seg.atepc', 'integrated_datasets/atepc_datasets/110.SemEval/114.restaurant14/Restaurants_Test_Gold.xml.seg.atepc', 'integrated_datasets/atepc_datasets/110.SemEval/116.restaurant16/restaurant_test.raw.atepc', 'integrated_datasets/atepc_datasets/101.ACL_Twitter/acl-14-short-data/test.raw.atepc', 'integrated_datasets/atepc_datasets/109.MAMS/test.xml.dat.atepc', 'integrated_datasets/atepc_datasets/117.Television/Television_Test_Gold.xml.seg.atepc', 'integrated_datasets/atepc_datasets/118.TShirt/Menstshirt_Test_Gold.xml.seg.atepc', 'integrated_datasets/atepc_datasets/119.Yelp/yelp.test.txt.atepc', 'integrated_datasets/atepc_datasets/121.MOOC_En/mooc-en.test.txt.atepc'], 'valid': ['integrated_datasets/atepc_datasets/109.MAMS/valid.xml.dat.atepc']}\t-->\tCalling Count:54\n",
      "dataset_name:English\t-->\tCalling Count:21\n",
      "device:cpu\t-->\tCalling Count:635061\n",
      "device_name:NVIDIA GeForce RTX 3090\t-->\tCalling Count:0\n",
      "dropout:0.5\t-->\tCalling Count:2\n",
      "dynamic_truncate:True\t-->\tCalling Count:79070\n",
      "embed_dim:768\t-->\tCalling Count:0\n",
      "evaluate_begin:0\t-->\tCalling Count:50\n",
      "gradient_accumulation_steps:1\t-->\tCalling Count:3\n",
      "hidden_dim:768\t-->\tCalling Count:12\n",
      "index_to_IOB_label:{1: 'B-ASP', 2: 'I-ASP', 3: 'O', 4: '[CLS]', 5: '[SEP]'}\t-->\tCalling Count:0\n",
      "index_to_label:{0: 'Negative', 1: 'Neutral', 2: 'Positive'}\t-->\tCalling Count:2\n",
      "initializer:xavier_uniform_\t-->\tCalling Count:0\n",
      "l2reg:1e-84\t-->\tCalling Count:2\n",
      "label_list:['B-ASP', 'I-ASP', 'O', '[CLS]', '[SEP]']\t-->\tCalling Count:8101957\n",
      "label_to_index:{'Negative': 0, 'Neutral': 1, 'Positive': 2}\t-->\tCalling Count:0\n",
      "lcf:cdw\t-->\tCalling Count:141137\n",
      "learning_rate:1e-05\t-->\tCalling Count:1\n",
      "log_step:2064\t-->\tCalling Count:50570\n",
      "max_seq_len:80\t-->\tCalling Count:417867\n",
      "max_test_metrics:{'max_apc_test_acc': 85.4, 'max_apc_test_f1': 82.79, 'max_ate_test_f1': 81.4}\t-->\tCalling Count:357\n",
      "metrics_of_this_checkpoint:{'apc_acc': 85.4, 'apc_f1': 82.53, 'ate_f1': 80.19}\t-->\tCalling Count:147\n",
      "model:<class 'pyabsa.core.atepc.models.fast_lcf_atepc.FAST_LCF_ATEPC'>\t-->\tCalling Count:6\n",
      "model_name:fast_lcf_atepc\t-->\tCalling Count:39621\n",
      "model_path_to_save:checkpoints\t-->\tCalling Count:37\n",
      "num_epoch:30\t-->\tCalling Count:2\n",
      "num_labels:6\t-->\tCalling Count:6\n",
      "optimizer:adamw\t-->\tCalling Count:2\n",
      "patience:99999\t-->\tCalling Count:18\n",
      "polarities_dim:3\t-->\tCalling Count:51\n",
      "pretrained_bert:microsoft/deberta-v3-base\t-->\tCalling Count:7\n",
      "save_mode:1\t-->\tCalling Count:33\n",
      "seed:52\t-->\tCalling Count:7\n",
      "sep_indices:2\t-->\tCalling Count:1128227\n",
      "show_metric:False\t-->\tCalling Count:0\n",
      "spacy_model:en_core_web_sm\t-->\tCalling Count:3\n",
      "srd_alignment:True\t-->\tCalling Count:0\n",
      "use_bert_spc:True\t-->\tCalling Count:90552\n",
      "use_syntax_based_SRD:False\t-->\tCalling Count:39535\n",
      "warmup_step:-1\t-->\tCalling Count:50569\n",
      "window:lr\t-->\tCalling Count:0\n"
     ]
    }
   ],
   "source": [
    "aspect_extractor = ATEPCCheckpointManager.get_aspect_extractor(checkpoint='english', auto_device=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:00<00:00, 2132.96it/s, preparing apc inference dataloader...]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, extracting aspect terms...]d:\\ANACONDA\\envs\\ml\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.84s/it, extracting aspect terms...]\n",
      "d:\\ANACONDA\\envs\\ml\\lib\\site-packages\\pyabsa\\core\\atepc\\prediction\\aspect_extractor.py:360: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\Users\\builder\\tkoch\\workspace\\pytorch\\pytorch_1647970138273\\work\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  lcf_cdm_vec = torch.tensor([f.lcf_cdm_vec for f in infer_features], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of aspect term extraction have been saved in f:\\PURECLONES\\AI-in-Classics\\src\\SentimentAnalysisTest\\atepc_inference.result.json\n",
      "Example 0: foreign\n",
      "Example 1: I miss you\n",
      "Example 2: stranger\n",
      "Example 3: barbarian\n",
      "Example 4: barbarize barbarize\n",
      "Example 5: Greekize\n",
      "Example 6: Greek\n",
      "Example 7: Greek\n",
      "Example 8: I ' m talking\n",
      "Example 9: I am antiquing\n",
      "Example 10: barbarize\n",
      "Example 11: barbaricion\n",
      "Example 12: barbaric\n",
      "Example 13: barbarism\n",
      "Example 14: barbaric\n",
      "Example 15: barbarian\n",
      "Example 16: barbaric killer\n",
      "Example 17: barbarian\n",
      "Example 18: barbarostomies\n",
      "Example 19: brutality\n",
      "Example 20: I ' m barbaric\n",
      "Example 21: barbarian\n",
      "Example 22: barbarian\n",
      "Example 23: barbaric\n",
      "Example 24: ungrammatical\n",
      "Example 25: worms\n",
      "Example 26: I ' m talking\n",
      "Example 27: colonist\n",
      "Example 28: colonization\n",
      "Example 29: colonist\n",
      "Example 30: soloicophanes\n",
      "Example 31: municipality\n",
      "Example 32: published\n",
      "Example 33: citizen\n",
      "Example 34: state\n",
      "Example 35: wild - mouthed\n",
      "Example 36: Greek\n",
      "Example 37: woman\n",
      "Example 38: i slave\n",
      "Example 39: slave girls\n",
      "Example 40: slave driver\n",
      "Example 41: closets\n",
      "Example 42: dollar\n",
      "Example 43: work\n",
      "Example 44: slave\n",
      "Example 45: laborer\n",
      "Example 46: free slave\n",
      "Example 47: slave\n",
      "Example 48: job\n",
      "Example 49: jobs\n",
      "Example 50: I was working\n",
      "Example 51: worked\n",
      "Example 52: maid\n",
      "Example 53: I work\n",
      "Example 54: chores\n",
      "Example 55: doulidion\n",
      "Example 56: servile\n",
      "Example 57: worker\n",
      "Example 58: work\n",
      "Example 59: Servant\n",
      "Example 60: servant\n",
      "Example 61: of slaves\n",
      "Example 62: slave teacher\n",
      "Example 63: servant\n",
      "Example 64: I am enslaved\n",
      "Example 65: slavery\n",
      "Example 66: slave battles\n",
      "Example 67: laborer\n",
      "Example 68: labor mix\n",
      "Example 69: I enslave\n",
      "Example 70: slave worker\n",
      "Example 71: slavish\n",
      "Example 72: subservience\n",
      "Example 73: servile\n",
      "Example 74: slave\n",
      "Example 75: servile\n",
      "Example 76: slavish\n",
      "Example 77: slavish\n",
      "Example 78: servile\n",
      "Example 79: employment\n",
      "Example 80: servile\n",
      "Example 81: Roman\n",
      "Example 82: foreign\n",
      "Example 83: alienation\n",
      "Example 84: foreigner\n",
      "Example 85: foreign\n",
      "Example 86: barbaric\n",
      "Example 87: barbaric ,\n",
      "Example 88: barbaric killer\n",
      "Example 89: illegitimate\n",
      "Example 90: nation\n",
      "Example 91: female\n",
      "Example 92: male\n",
      "Example 93: foreign\n",
      "Example 94: language\n",
      "Example 95: tongue\n",
      "Example 96: dialect\n",
      "Example 97: Attic\n",
      "Example 98: Atticize\n",
      "Example 99: Atticist\n",
      "Example 100: foreign languages\n",
      "Example 101: foreign language\n",
      "Example 102: foreign\n",
      "Example 103: alienation\n",
      "Example 104: Egyptian\n",
      "Example 105: tyrant\n",
      "Example 106: Persian\n",
      "Example 107: colour\n",
      "Example 108: law\n",
      "Example 109: custom\n",
      "Example 110: genus\n",
      "Example 111: courtesy\n",
      "Example 112: I hate her\n",
      "Example 113: I love him\n",
      "Example 114: i don ' t love him\n",
      "Example 115: I don ' t hate him\n",
      "Example 116: he is barbaric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\envs\\ml\\lib\\site-packages\\pyabsa\\core\\atepc\\prediction\\aspect_extractor.py:408: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = [float(x) for x in F.softmax(i_apc_logits).cpu().numpy().tolist()]\n"
     ]
    }
   ],
   "source": [
    "inference_source = translated_array\n",
    "atepc_result = aspect_extractor.extract_aspect(inference_source=inference_source,pred_sentiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'foreign',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['foreign'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'I miss you',\n",
       "  'IOB': ['O', 'O', 'O'],\n",
       "  'tokens': ['I', 'miss', 'you'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'stranger',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['stranger'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarian',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbarian'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarize barbarize',\n",
       "  'IOB': ['B-ASP', 'O'],\n",
       "  'tokens': ['barbarize', 'barbarize'],\n",
       "  'aspect': ['barbarize'],\n",
       "  'position': [[0]],\n",
       "  'sentiment': ['Positive'],\n",
       "  'probs': [[0.0009770119795575738,\n",
       "    0.0049799056723713875,\n",
       "    0.9940430521965027]],\n",
       "  'confidence': [0.9940430521965027]},\n",
       " {'sentence': 'Greekize',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Greekize'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Greek',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Greek'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Greek',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Greek'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': \"I ' m talking\",\n",
       "  'IOB': ['O', 'O', 'O', 'O'],\n",
       "  'tokens': ['I', \"'\", 'm', 'talking'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'I am antiquing',\n",
       "  'IOB': ['O', 'O', 'O'],\n",
       "  'tokens': ['I', 'am', 'antiquing'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarize',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['barbarize'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbaricion',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbaricion'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbaric',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbaric'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarism',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbarism'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbaric',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbaric'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarian',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbarian'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbaric killer',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['barbaric', 'killer'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarian',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbarian'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarostomies',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['barbarostomies'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'brutality',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['brutality'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': \"I ' m barbaric\",\n",
       "  'IOB': ['O', 'O', 'O', 'O'],\n",
       "  'tokens': ['I', \"'\", 'm', 'barbaric'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarian',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbarian'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbarian',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbarian'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbaric',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbaric'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'ungrammatical',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['ungrammatical'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'worms',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['worms'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': \"I ' m talking\",\n",
       "  'IOB': ['O', 'O', 'O', 'O'],\n",
       "  'tokens': ['I', \"'\", 'm', 'talking'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'colonist',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['colonist'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'colonization',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['colonization'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'colonist',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['colonist'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'soloicophanes',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['soloicophanes'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'municipality',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['municipality'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'published',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['published'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'citizen',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['citizen'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'state',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['state'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'wild - mouthed',\n",
       "  'IOB': ['O', 'O', 'O'],\n",
       "  'tokens': ['wild', '-', 'mouthed'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Greek',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Greek'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'woman',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['woman'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'i slave',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['i', 'slave'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slave girls',\n",
       "  'IOB': ['B-ASP', 'O'],\n",
       "  'tokens': ['slave', 'girls'],\n",
       "  'aspect': ['slave'],\n",
       "  'position': [[0]],\n",
       "  'sentiment': ['Negative'],\n",
       "  'probs': [[0.9911102056503296, 0.0003356951929163188, 0.00855413917452097]],\n",
       "  'confidence': [0.9911102056503296]},\n",
       " {'sentence': 'slave driver',\n",
       "  'IOB': ['O', 'B-ASP'],\n",
       "  'tokens': ['slave', 'driver'],\n",
       "  'aspect': ['driver'],\n",
       "  'position': [[1]],\n",
       "  'sentiment': ['Neutral'],\n",
       "  'probs': [[0.3565349280834198, 0.6429106593132019, 0.0005543906008824706]],\n",
       "  'confidence': [0.6429106593132019]},\n",
       " {'sentence': 'closets',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['closets'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'dollar',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['dollar'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'work',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['work'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slave',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['slave'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'laborer',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['laborer'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'free slave',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['free', 'slave'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slave',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['slave'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'job',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['job'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'jobs',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['jobs'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'I was working',\n",
       "  'IOB': ['O', 'O', 'O'],\n",
       "  'tokens': ['I', 'was', 'working'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'worked',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['worked'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'maid',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['maid'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'I work',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['I', 'work'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'chores',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['chores'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'doulidion',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['doulidion'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'servile',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['servile'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'worker',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['worker'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'work',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['work'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Servant',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['Servant'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'servant',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['servant'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'of slaves',\n",
       "  'IOB': ['O', 'B-ASP'],\n",
       "  'tokens': ['of', 'slaves'],\n",
       "  'aspect': ['slaves'],\n",
       "  'position': [[1]],\n",
       "  'sentiment': ['Negative'],\n",
       "  'probs': [[0.5465329885482788, 0.3912799060344696, 0.062187157571315765]],\n",
       "  'confidence': [0.5465329885482788]},\n",
       " {'sentence': 'slave teacher',\n",
       "  'IOB': ['O', 'B-ASP'],\n",
       "  'tokens': ['slave', 'teacher'],\n",
       "  'aspect': ['teacher'],\n",
       "  'position': [[1]],\n",
       "  'sentiment': ['Negative'],\n",
       "  'probs': [[0.9985302686691284,\n",
       "    0.0009832167997956276,\n",
       "    0.00048645984497852623]],\n",
       "  'confidence': [0.9985302686691284]},\n",
       " {'sentence': 'servant',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['servant'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'I am enslaved',\n",
       "  'IOB': ['O', 'O', 'O'],\n",
       "  'tokens': ['I', 'am', 'enslaved'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slavery',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['slavery'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slave battles',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['slave', 'battles'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'laborer',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['laborer'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'labor mix',\n",
       "  'IOB': ['B-ASP', 'I-ASP'],\n",
       "  'tokens': ['labor', 'mix'],\n",
       "  'aspect': ['labor mix'],\n",
       "  'position': [[0, 1]],\n",
       "  'sentiment': ['Neutral'],\n",
       "  'probs': [[0.07242178916931152, 0.7765625715255737, 0.15101563930511475]],\n",
       "  'confidence': [0.7765625715255737]},\n",
       " {'sentence': 'I enslave',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['I', 'enslave'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slave worker',\n",
       "  'IOB': ['B-ASP', 'I-ASP'],\n",
       "  'tokens': ['slave', 'worker'],\n",
       "  'aspect': ['slave worker'],\n",
       "  'position': [[0, 1]],\n",
       "  'sentiment': ['Negative'],\n",
       "  'probs': [[0.7324596047401428, 0.018696127459406853, 0.2488442361354828]],\n",
       "  'confidence': [0.7324596047401428]},\n",
       " {'sentence': 'slavish',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['slavish'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'subservience',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['subservience'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'servile',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['servile'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slave',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['slave'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'servile',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['servile'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slavish',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['slavish'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'slavish',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['slavish'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'servile',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['servile'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'employment',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['employment'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'servile',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['servile'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Roman',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Roman'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'foreign',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['foreign'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'alienation',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['alienation'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'foreigner',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['foreigner'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'foreign',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['foreign'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbaric',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['barbaric'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbaric ,',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['barbaric', ','],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'barbaric killer',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['barbaric', 'killer'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'illegitimate',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['illegitimate'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'nation',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['nation'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'female',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['female'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'male',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['male'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'foreign',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['foreign'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'language',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['language'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'tongue',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['tongue'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'dialect',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['dialect'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Attic',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Attic'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Atticize',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Atticize'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Atticist',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Atticist'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'foreign languages',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['foreign', 'languages'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'foreign language',\n",
       "  'IOB': ['O', 'O'],\n",
       "  'tokens': ['foreign', 'language'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'foreign',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['foreign'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'alienation',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['alienation'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Egyptian',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['Egyptian'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'tyrant',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['tyrant'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'Persian',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['Persian'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'colour',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['colour'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'law',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['law'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'custom',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['custom'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'genus',\n",
       "  'IOB': ['O'],\n",
       "  'tokens': ['genus'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'courtesy',\n",
       "  'IOB': ['B-ASP'],\n",
       "  'tokens': ['courtesy'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'I hate her',\n",
       "  'IOB': ['O', 'O', 'O'],\n",
       "  'tokens': ['I', 'hate', 'her'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'I love him',\n",
       "  'IOB': ['O', 'O', 'O'],\n",
       "  'tokens': ['I', 'love', 'him'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': \"i don ' t love him\",\n",
       "  'IOB': ['O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  'tokens': ['i', 'don', \"'\", 't', 'love', 'him'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': \"I don ' t hate him\",\n",
       "  'IOB': ['O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  'tokens': ['I', 'don', \"'\", 't', 'hate', 'him'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []},\n",
       " {'sentence': 'he is barbaric',\n",
       "  'IOB': ['O', 'O', 'O'],\n",
       "  'tokens': ['he', 'is', 'barbaric'],\n",
       "  'aspect': [],\n",
       "  'position': [],\n",
       "  'sentiment': [],\n",
       "  'probs': [],\n",
       "  'confidence': []}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atepc_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949b91785ef6ac895db2af1a779a6a5dd5fe0174f46c0229c21313f182b262bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
