{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἀάατον\n"
     ]
    }
   ],
   "source": [
    "#make the CSV for the lemmas DF \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "bases_src = 'Raw_XML/MorpheusUnicode.xml'\n",
    "\n",
    "tree = ET.parse(bases_src)\n",
    "root = tree.getroot()\n",
    "\n",
    "#make the stuff that will form the headers \n",
    "sequence_num = []\n",
    "text = []\n",
    "bare_text = []\n",
    "base_form = []\n",
    "bare_base_form = []\n",
    "morph_code = []\n",
    "id = []\n",
    "definition = []\n",
    "\n",
    "print(root[0][1].text)\n",
    "\n",
    "for row in root:\n",
    "    sequence_num.append(row[0].text)\n",
    "    text.append(row[1].text)\n",
    "    bare_text.append(row[2].text)\n",
    "    base_form.append(row[3].text)\n",
    "    bare_base_form.append(row[4].text)\n",
    "    morph_code.append(row[5].text)\n",
    "    id.append(row[6].text)\n",
    "    definition.append(row[7].text)\n",
    "\n",
    "\n",
    "\n",
    "dictionary = {\"id\": id, \"text\": text, \"bare_text\": bare_text, \"sequence_num\": sequence_num, \"morph_code\": morph_code, \"base_form\": base_form, \"bare_base_form\": bare_base_form, \"definition\": definition}\n",
    "df = pd.DataFrame(dictionary)\n",
    "df.to_csv(\"Dictionary_Dataframes/greek_words.csv\", sep = \"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row[0] = id\n",
    "row[1] = text\n",
    "row[2] = bare-text\n",
    "row[3] = seq # \n",
    "row[4] = lang id -- 2 is grk; 3 is ltn\n",
    "row[5] = definition\n",
    "\n",
    "Delimiter cant be: ,;:\\/|?}[]() because of existance in files\n",
    "it CAN be { so that is what current delim is in CSV files \n",
    "\n",
    "instances OF lemma_lang_id = 3 matches number of rows in CSV!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    bare_text                                         definition\n",
      "0      36489            A                                                NaN\n",
      "1      36490            a                            from, away from, out of\n",
      "2      36491      abactus                            driven away, driven off\n",
      "3      36492       abacus   a table of precious material for the display ...\n",
      "4      36493  abalienatio              a transfer of property, sale, cession\n",
      "...      ...          ...                                                ...\n",
      "17568  54057     Zephyrus         a gentle west wind, western breeze, zephyr\n",
      "17569  54058    zmaragdus                                                NaN\n",
      "17570  54059     zodiacus                                         the zodiac\n",
      "17571  54060         zona                       a woman's girdle, belt, zone\n",
      "17572  54061     zonarius                             of a belt, of a girdle\n",
      "\n",
      "[17573 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#now check importing db from csv\n",
    "import pandas as pd \n",
    "df = pd.read_csv(\"lemmas_abr.csv\", sep = \"{\")\n",
    "del df['Unnamed: 0']\n",
    "#df usable from this point forward!\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n"
     ]
    }
   ],
   "source": [
    "#now time for parses \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "bases_src = 'Raw_XML/hib_parses.xml'\n",
    "\n",
    "tree = ET.parse(bases_src)\n",
    "root = tree.getroot()\n",
    "\n",
    "#make the stuff that will form the headers \n",
    "id = []\n",
    "word_id = []\n",
    "morph_code = []\n",
    "exp_text = []\n",
    "text = []\n",
    "bare_text = []\n",
    "dialects = []\n",
    "misc_features = []\n",
    "print(root[0][1][0][1].text)\n",
    "#only add to CSV if latin -- no grk\n",
    "for row in root[0][1]:\n",
    "    word_id.append(row[0].text)\n",
    "    id.append(row[1].text)\n",
    "    morph_code.append(row[2].text)\n",
    "    exp_text.append(row[3].text)\n",
    "    text.append(row[4].text)\n",
    "    bare_text.append(row[5].text)\n",
    "    dialects.append(row[6].text)\n",
    "    misc_features.append(row[7].text)\n",
    "\n",
    "dict = {\n",
    "    \"id\": id, \n",
    "    \"word_id\": word_id, \n",
    "    \"morph_code\": morph_code, \n",
    "    \"exp_text\": exp_text, \n",
    "    \"text\": text,\n",
    "    \"bare_text\": bare_text,\n",
    "    \"dialects\": dialects,\n",
    "    \"misc_features\": misc_features}\n",
    "dict_abr = {\n",
    "    \"id\": id, \n",
    "    \"word_id\": word_id, \n",
    "    \"morph_code\": morph_code, \n",
    "    \"bare_text\": bare_text}\n",
    "df = pd.DataFrame(dict)\n",
    "df_abr = pd.DataFrame(dict_abr)\n",
    "df.to_csv(\"Dictionary_Dataframes/parses.csv\", sep = \"{\")\n",
    "df_abr.to_csv(\"Dictionary_Dataframes/parses_abr.csv\", sep = \"{\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m remove \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39m#words with the same morph code and bare_text without enclitic\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m df2 \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m\"\u001b[39;49m\u001b[39mmorph_code\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39;49m morph]\n\u001b[1;32m     37\u001b[0m df2 \u001b[39m=\u001b[39m df2\u001b[39m.\u001b[39mloc[df2[\u001b[39m\"\u001b[39m\u001b[39mbare_text\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m check_against]\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m df2\u001b[39m.\u001b[39miterrows():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6245\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:287\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    286\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    289\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:75\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row[0] = word id\n",
    "row[1] = id <-- HOW WE MATCH TO OTHER DF \n",
    "row[2] = morphological code\n",
    "row[3] = expanded form\n",
    "row[4] = form\n",
    "row[5] = bare_form\n",
    "row[6] = dialects\n",
    "row[7] = misc features\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
