{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Search Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for documents or indexes of word occurrences inside documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4, csv,json, multiprocessing as mp, numpy as np, os, pandas as pd, pickle, re, requests, tqdm\n",
    "from inspect import signature\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "from termcolor import colored, cprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipycache\n",
    "from IPython.utils.traitlets import Unicode\n",
    "%load_ext ipycache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coloring options\n",
    "line_color = 'green'\n",
    "text_color = 'magenta'\n",
    "reference_color = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environment variables from .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "metadata_path=os.getenv(key='metadata_path')\n",
    "metadata_df_path=os.getenv(key='metadata_df_path')\n",
    "corpus_path=os.getenv(key='corpus_path')\n",
    "\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text=f'Metadata path: {metadata_path}', color=text_color)\n",
    "cprint(text=f'Metadata dataframe path: {metadata_df_path}', color=text_color)\n",
    "cprint(text=f'Corpus path: {corpus_path}', color=text_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load metadata for First1KGreek project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = None\n",
    "\n",
    "try:\n",
    "    metadata_df = pickle.load(file=open(file='metadata_df.pkl', mode='rb'))['metadata_df']\n",
    "\n",
    "except:\n",
    "    metadata_csv_reader = csv.reader(open(file=metadata_path, mode='r', encoding='utf-8'))\n",
    "    columns = next(metadata_csv_reader)\n",
    "    metadata_df = pd.DataFrame(\n",
    "        data=np.asarray(a=list(metadata_csv_reader)),\n",
    "        columns=columns\n",
    "    )\n",
    "\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text='metadata_df:', color=text_color)\n",
    "cprint(text='-' * 100, color=line_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cache metadata_df.pkl metadata_df --force\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Latin text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *From TXT File*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(filename: str):\n",
    "    \"\"\"\n",
    "    Extract text from a .txt file.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): Path of file to load.\n",
    "\n",
    "    Returns:\n",
    "        str: Text loaded from file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path=filename):\n",
    "        raise ValueError(f'The path {filename} does not exist.')\n",
    "\n",
    "    text = open(file=filename, mode='r').read()\n",
    "    return text\n",
    "\n",
    "filename = '/mnt/d/share/Using-AI-to-Trace-the-History-of-Race-and-Inequality/src/sample_text/latin/urn_cts_greekLit_stoa0146d.stoa001.opp-lat11.txt'\n",
    "text = load_txt(filename=filename)\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text='Loading from TXT file:', color=text_color)\n",
    "cprint(text=filename, color=reference_color)\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text=text, color=text_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *From URI*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uri(uri: str):\n",
    "    \"\"\"\n",
    "    Load text from URI.\n",
    "\n",
    "    Parameters:\n",
    "        uri (str): URI link to text online.\n",
    "\n",
    "    Returns:\n",
    "        str: Text loaded from URI.\n",
    "    \"\"\"\n",
    "    req = requests.get(url=uri)\n",
    "    return req.text\n",
    "\n",
    "uri = 'https://scaife.perseus.org/library/passage/urn:cts:greekLit:stoa0146d.stoa001.opp-lat1:1/text/'\n",
    "text = load_uri(uri=uri)\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text='Loading from URI:', color=text_color)\n",
    "cprint(text=uri, color=reference_color)\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text=text, color=text_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *From URN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_urn(urn: str):\n",
    "    \"\"\"\n",
    "    Load text from URN.\n",
    "\n",
    "    Parameters:\n",
    "        urn (str): URN link that identifies specific work.\n",
    "\n",
    "    Returns:\n",
    "        str: Text loaded from URI.\n",
    "    \"\"\"\n",
    "    idx = metadata_df.index[metadata_df['URN'] == urn][0]\n",
    "    url = f'https://scaife.perseus.org/library/passage/{metadata_df.at[idx, \"URL\"].split(\"/\")[-2]}/text/'\n",
    "    req = requests.get(url=url)\n",
    "    \n",
    "    return req.text\n",
    "\n",
    "urn = 'urn:cts:greekLit:stoa0146d.stoa001.opp-lat1'\n",
    "text = load_urn(urn=urn)\n",
    "url = f'https://scaife.perseus.org/library/passage/{metadata_df.at[0, \"URL\"].split(\"/\")[-2]}/text/'\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text='Loading from URN:', color=text_color)\n",
    "cprint(text=urn, color=reference_color)\n",
    "cprint(text=url, color=text_color)\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text=text, color=text_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create analyzer for text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.lang import has_stemmer, languages\n",
    "from whoosh.analysis import SpaceSeparatedTokenizer, LowercaseFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for Latin availability for analyzer\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text='Available languages for LanguageAnalyzer:', color=text_color)\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "pprint(languages)\n",
    "\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text=f'Latin is available? {has_stemmer(lang=\"lat\")}', color=text_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SpaceSeparatedTokenizer() | LowercaseFilter()\n",
    "for token in analyzer(value=text):\n",
    "    pprint(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in, exists_in, open_dir\n",
    "from whoosh.fields import Schema, ID, KEYWORD, NUMERIC, TEXT\n",
    "from whoosh.formats import Positions\n",
    "from whoosh.qparser import QueryParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_upload = widgets.FileUpload(\n",
    "    accept='.json, .pkl, .txt',\n",
    "    multiple=False,\n",
    ")\n",
    "\n",
    "display(schema_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_bytestr = list(schema_upload.value.values())[0]['content']\n",
    "schema_dict = json.loads(s=schema_bytestr)\n",
    "for key, val in schema_dict.items():\n",
    "    schema_dict[key] = eval(val)\n",
    "\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text='Dictionary form of uploaded schema:', color=text_color)\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "pprint(schema_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Schema(**schema_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(\n",
    "    index = NUMERIC(\n",
    "        bits=64,\n",
    "        numtype='int',\n",
    "        signed=False,\n",
    "        sortable=True,\n",
    "        stored=True,\n",
    "        unique=True\n",
    "    ),\n",
    "#     url = ID(\n",
    "#         sortable=False,\n",
    "#         stored=True,\n",
    "#         unique=True\n",
    "#     ),\n",
    "#     title=TEXT(\n",
    "#         chars=True,\n",
    "#         phrase=True,\n",
    "#         sortable=True,\n",
    "#         stored=True\n",
    "#     ),\n",
    "#     author=TEXT(\n",
    "#         chars=True,\n",
    "#         phrase=True,\n",
    "#         sortable=True,\n",
    "#         stored=True\n",
    "#     ),\n",
    "#     languages=KEYWORD(\n",
    "#         commas=True,\n",
    "#         lowercase=True,\n",
    "#         scorable=False,\n",
    "#         sortable=False,\n",
    "#         stored=True,\n",
    "#         unique=False\n",
    "#     ),\n",
    "#     keywords=KEYWORD(\n",
    "#         commas=True,\n",
    "#         lowercase=True,\n",
    "#         scorable=True,\n",
    "#         sortable=True,\n",
    "#         stored=True,\n",
    "#         unique=False\n",
    "#     ),\n",
    "    content=TEXT(  \n",
    "        analyzer=analyzer,\n",
    "        chars=True,\n",
    "        phrase=True,\n",
    "        sortable=False,\n",
    "        stored=False,\n",
    "\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create or load index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirname_dropdown = widgets.Dropdown(\n",
    "    options=np.asarray(a=list(filter(lambda x: os.path.isdir(s=x), os.listdir(path='.')))),\n",
    "    description='dirname',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(dirname_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writelock_files = list(filter(\n",
    "    lambda x: re.match(pattern='.+_WRITELOCK', string=x), \n",
    "    list([x.decode() for x in os.listdir(path=dirname_dropdown.value)]))\n",
    ")\n",
    "\n",
    "indexname_options = np.asarray(a=list(map(\n",
    "    lambda x: x[:-len('_WRITELOCK')],\n",
    "    writelock_files))\n",
    ")\n",
    "\n",
    "indexname_dropdown = widgets.Dropdown(\n",
    "    options=indexname_options,\n",
    "    description='indexname',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(indexname_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = None\n",
    "\n",
    "try:\n",
    "    ix = open_dir(\n",
    "        dirname=str(dirname_dropdown.value),\n",
    "        indexname=indexname_dropdown.value\n",
    "    )\n",
    "\n",
    "except:\n",
    "    raise Exception\n",
    "    ix = create_in(dirname='indexes/',\n",
    "                  schema=schema,\n",
    "                  indexname='latin_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index documents."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from whoosh.writing import AsyncWriter, BufferedWriter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "corpus = pickle.load(file=open(file=corpus_path, mode='rb'))['corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprint(text='-' * 100, color=line_color)\n",
    "cprint(text='Enter number of processors for indexing:', color=text_color)\n",
    "cprint(text='-' * 100, color=line_color)\n",
    "procs_select = widgets.IntSlider(\n",
    "    value=64,\n",
    "    min=1,\n",
    "    max=128,\n",
    "    step=1,\n",
    "    description='Number of processors to use during indexing.',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(procs_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(tqdm.tqdm(list([row[1] for row in list(metadata_df.iterrows())]))):\n",
    "    writer = ix.writer()\n",
    "    writer.add_document(\n",
    "        index = idx,\n",
    "#         url = row['URL'],\n",
    "#         title = row['Work'],\n",
    "#         author = row['Workgroup'],\n",
    "#         languages = row['Language'],\n",
    "#         keywords = u'',\n",
    "        content = load_urn(urn=row['URN'])\n",
    "    )\n",
    "\n",
    "    writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latin_queries = list([query.strip() for query in open(file='latin_queries.txt').readlines()])\n",
    "pprint(latin_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with ix.searcher() as searcher:\n",
    "    query = QueryParser(\n",
    "        fieldname='index',\n",
    "        schema=ix.schema\n",
    "    ).parse(\n",
    "#         text=' '.join(latin_queries),\n",
    "        text='*'\n",
    "    )\n",
    "    results = searcher.search(q=query)\n",
    "    pprint(list(results))\n",
    "#     pprint(signature(obj=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
