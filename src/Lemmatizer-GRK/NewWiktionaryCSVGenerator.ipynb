{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from io import StringIO\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "    \"\"\"Remove accents from a given string.\"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def generate_morph_code(part_of_speech, person, number, tense, mood, voice, gender, case, degree):\n",
    "    \"\"\"\n",
    "    Generate a morph code based on grammatical features according to the 9-position key.\n",
    "    \"\"\"\n",
    "    morph_code = f\"{part_of_speech}{person}{number}{tense}{mood}{voice}{gender}{case}{degree}\"\n",
    "    return morph_code\n",
    "\n",
    "def normalize_word(word):\n",
    "    \"\"\"Normalize a Greek word by removing accents and converting to lowercase.\"\"\"\n",
    "    return strip_accents(word).lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_noun_table(df, base_word, gender, sequence_num_start, definition):\n",
    "    \"\"\"Parse the noun inflection table and extract forms along with their grammatical features.\"\"\"\n",
    "    # Map for cases and numbers\n",
    "    case_map = {\n",
    "        'nominative': 'n',\n",
    "        'genitive': 'g',\n",
    "        'dative': 'd',\n",
    "        'accusative': 'a',\n",
    "        'vocative': 'v',\n",
    "        'ablative': 'b',\n",
    "        'locative': 'l',\n",
    "        'instrumental': 'i',\n",
    "        'notes:': ''\n",
    "    }\n",
    "    number_map = {\n",
    "        'singular': 's',\n",
    "        'dual': 'd',\n",
    "        'plural': 'p'\n",
    "    }\n",
    "\n",
    "    forms = []\n",
    "    sequence_num = sequence_num_start\n",
    "\n",
    "    # Clean the DataFrame headers\n",
    "    df.columns = [str(col).lower().strip() for col in df.columns]\n",
    "\n",
    "    # The first column should be cases\n",
    "    cases = df.iloc[:, 0].astype(str).str.lower().str.strip()\n",
    "    # The rest of the columns are numbers\n",
    "    numbers = [str(col).lower().strip() for col in df.columns[1:]]\n",
    "\n",
    "    for idx, case in enumerate(cases):\n",
    "        case = case.strip()\n",
    "        case_key = case_map.get(case, '-')\n",
    "        if case_key == '':\n",
    "            continue  # Skip notes or irrelevant rows\n",
    "        for col_idx, num_col in enumerate(numbers):\n",
    "            num_col = num_col.strip()\n",
    "            number_key = number_map.get(num_col, '-')\n",
    "            if number_key == '-':\n",
    "                continue\n",
    "            form = df.iloc[idx, col_idx + 1]\n",
    "            if isinstance(form, str):\n",
    "                form = form.strip()\n",
    "                if form != '':\n",
    "                    bare_text = strip_accents(form)\n",
    "                    bare_base_form = strip_accents(base_word)\n",
    "                    morph_code = generate_morph_code(\n",
    "                        part_of_speech='n',\n",
    "                        person='-',\n",
    "                        number=number_key,\n",
    "                        tense='-',\n",
    "                        mood='-',\n",
    "                        voice='-',\n",
    "                        gender=gender,\n",
    "                        case=case_key,\n",
    "                        degree='-'\n",
    "                    )\n",
    "                    form_entry = {\n",
    "                        'id': sequence_num,\n",
    "                        'text': form,\n",
    "                        'bare_text': bare_text,\n",
    "                        'sequence_num': sequence_num,\n",
    "                        'morph_code': morph_code,\n",
    "                        'base_form': base_word,\n",
    "                        'bare_base_form': bare_base_form,\n",
    "                        'definition': definition\n",
    "                    }\n",
    "                    forms.append(form_entry)\n",
    "                    sequence_num += 1\n",
    "    return forms\n",
    "\n",
    "def parse_adjective_table(df, base_word, sequence_num_start, definition):\n",
    "    \"\"\"\n",
    "    Parse the adjective inflection table and extract forms along with their grammatical features.\n",
    "    Handles tables with extra header rows and reconstructs columns accordingly.\n",
    "    \"\"\"\n",
    "    # Map for degrees\n",
    "    degree_map = {\n",
    "        'positive': 'p',\n",
    "        'comparative': 'c',\n",
    "        'superlative': 's'\n",
    "    }\n",
    "    # Map for genders\n",
    "    gender_map = {\n",
    "        'masculine': 'm',\n",
    "        'feminine': 'f',\n",
    "        'masculine / feminine': 'mf',\n",
    "        'masculine/feminine': 'mf',\n",
    "        'neuter': 'n'\n",
    "    }\n",
    "    # Map for cases\n",
    "    case_map = {\n",
    "        'nominative': 'n',\n",
    "        'genitive': 'g',\n",
    "        'dative': 'd',\n",
    "        'accusative': 'a',\n",
    "        'vocative': 'v',\n",
    "        'ablative': 'b',\n",
    "        'locative': 'l',\n",
    "        'instrumental': 'i',\n",
    "        'notes:': ''\n",
    "    }\n",
    "    # Map for numbers\n",
    "    number_map = {\n",
    "        'singular': 's',\n",
    "        'dual': 'd',\n",
    "        'plural': 'p'\n",
    "    }\n",
    "\n",
    "    forms = []\n",
    "    sequence_num = sequence_num_start\n",
    "\n",
    "    # Adjust the DataFrame\n",
    "    # Set columns to the first row\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.drop(df.index[0])\n",
    "\n",
    "    # Clean up column names\n",
    "    df.columns = [str(col).strip().lower() for col in df.columns]\n",
    "    # Drop columns with 'nan' names\n",
    "    df = df.loc[:, df.columns != 'nan']\n",
    "\n",
    "    # Reconstruct df.columns to include 'number' and 'gender'\n",
    "    df_columns = []\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        if idx == 0:\n",
    "            # First column is 'case'\n",
    "            df_columns.append('case')\n",
    "        else:\n",
    "            if idx in [1, 2]:\n",
    "                number = 'singular'\n",
    "            elif idx in [3, 4]:\n",
    "                number = 'dual'\n",
    "            elif idx in [5, 6]:\n",
    "                number = 'plural'\n",
    "            else:\n",
    "                number = ''\n",
    "            gender = col.strip().lower()\n",
    "            df_columns.append(f\"{number} {gender}\")\n",
    "\n",
    "    df.columns = df_columns\n",
    "\n",
    "    # Extract cases\n",
    "    cases = df['case'].str.lower().str.strip()\n",
    "\n",
    "    for idx, case in enumerate(cases):\n",
    "        case_key = case_map.get(case, '-')\n",
    "        if case_key == '':\n",
    "            continue  # Skip notes or irrelevant rows\n",
    "\n",
    "        for col_idx in range(1, len(df.columns)):\n",
    "            col_name = df.columns[col_idx]\n",
    "            tokens = col_name.split()\n",
    "            if len(tokens) >= 2:\n",
    "                number_name = tokens[0]\n",
    "                gender_name = ' '.join(tokens[1:])\n",
    "            else:\n",
    "                continue  # Cannot extract number and gender\n",
    "\n",
    "            number_key = number_map.get(number_name.strip(), '-')\n",
    "            gender_key = gender_map.get(gender_name.strip(), '-')\n",
    "            if number_key == '-' or gender_key == '-':\n",
    "                continue\n",
    "\n",
    "            form = df.iloc[idx, col_idx]\n",
    "            if isinstance(form, str):\n",
    "                form = form.strip()\n",
    "                if form != '':\n",
    "                    bare_text = strip_accents(form)\n",
    "                    bare_base_form = strip_accents(base_word)\n",
    "                    # Assume degree is 'positive' unless specified\n",
    "                    degree_key = 'p'\n",
    "                    # Handle 'masculine / feminine' gender\n",
    "                    if gender_key == 'mf':\n",
    "                        genders = ['m', 'f']\n",
    "                    else:\n",
    "                        genders = [gender_key]\n",
    "                    for gender in genders:\n",
    "                        morph_code = generate_morph_code(\n",
    "                            part_of_speech='a',\n",
    "                            person='-',\n",
    "                            number=number_key,\n",
    "                            tense='-',\n",
    "                            mood='-',\n",
    "                            voice='-',\n",
    "                            gender=gender,\n",
    "                            case=case_key,\n",
    "                            degree=degree_key\n",
    "                        )\n",
    "                        form_entry = {\n",
    "                            'id': sequence_num,\n",
    "                            'text': form,\n",
    "                            'bare_text': bare_text,\n",
    "                            'sequence_num': sequence_num,\n",
    "                            'morph_code': morph_code,\n",
    "                            'base_form': base_word,\n",
    "                            'bare_base_form': bare_base_form,\n",
    "                            'definition': definition\n",
    "                        }\n",
    "                        forms.append(form_entry)\n",
    "                        sequence_num += 1\n",
    "\n",
    "    return forms\n",
    "\n",
    "\n",
    "def parse_verb_table(df, base_word, sequence_num_start, definition):\n",
    "    \"\"\"\n",
    "    Parse the verb inflection table and extract forms along with their grammatical features.\n",
    "    Handles tables with multiple header levels.\n",
    "    \"\"\"\n",
    "    # Maps for grammatical features\n",
    "    person_map = {\n",
    "        'first person': '1',\n",
    "        'second person': '2',\n",
    "        'third person': '3',\n",
    "    }\n",
    "    \n",
    "    number_map = {\n",
    "        'singular': 's',\n",
    "        'dual': 'd',\n",
    "        'plural': 'p'\n",
    "    }\n",
    "    \n",
    "    mood_map = {\n",
    "        'indicative': 'i',\n",
    "        'subjunctive': 's',\n",
    "        'optative': 'o',\n",
    "        'imperative': 'm',\n",
    "        'infinitive': 'n',\n",
    "        'participle': 'p'\n",
    "    }\n",
    "    \n",
    "    voice_map = {\n",
    "        'active': 'a',\n",
    "        'middle': 'm',\n",
    "        'passive': 'p',\n",
    "        'mediopassive': 'e'\n",
    "    }\n",
    "    \n",
    "    tense_map = {\n",
    "        'present': 'p',\n",
    "        'imperfect': 'i',\n",
    "        'future': 'f',\n",
    "        'aorist': 'a',\n",
    "        'perfect': 'r',\n",
    "        'pluperfect': 'l',\n",
    "        'future perfect': 't'\n",
    "    }\n",
    "    \n",
    "    forms = []\n",
    "    sequence_num = sequence_num_start\n",
    "\n",
    "    # Flatten MultiIndex columns\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [' '.join([str(s).strip().lower() for s in col if str(s) != 'nan']) for col in df.columns]\n",
    "    else:\n",
    "        df.columns = [col.lower().strip() for col in df.columns]\n",
    "\n",
    "    # Identify the grammatical features from the table\n",
    "    for col in df.columns:\n",
    "        if ' ' in col:\n",
    "            continue\n",
    "        if col in ['person', 'number', 'person / number']:\n",
    "            # This is the row index column\n",
    "            df.rename(columns={col: 'person_number'}, inplace=True)\n",
    "            break\n",
    "\n",
    "    # Extract mood, voice, tense from the table caption or nearby headers\n",
    "    # For this example, let's assume we have mood, voice, tense information passed to this function\n",
    "    # Alternatively, you can modify the code to extract these from the HTML as needed\n",
    "\n",
    "    # Since the tables are complex, we need to get mood, voice, tense from the column headers\n",
    "    columns_info = []\n",
    "    for col in df.columns:\n",
    "        if col == 'person_number':\n",
    "            columns_info.append({'column': col})\n",
    "            continue\n",
    "        features = {'column': col}\n",
    "        # Split the column name to extract features\n",
    "        tokens = col.split()\n",
    "        for token in tokens:\n",
    "            if token in mood_map:\n",
    "                features['mood'] = mood_map[token]\n",
    "            elif token in voice_map:\n",
    "                features['voice'] = voice_map[token]\n",
    "            elif token in tense_map:\n",
    "                features['tense'] = tense_map[token]\n",
    "        columns_info.append(features)\n",
    "\n",
    "    # Iterate over the rows to extract forms\n",
    "    for idx, row in df.iterrows():\n",
    "        person_number = str(row.get('person_number', '')).lower()\n",
    "        person = '-'\n",
    "        number = '-'\n",
    "        # Extract person and number from row labels\n",
    "        for pn in person_map:\n",
    "            if pn in person_number:\n",
    "                person = person_map[pn]\n",
    "                break\n",
    "        for num in number_map:\n",
    "            if num in person_number:\n",
    "                number = number_map[num]\n",
    "                break\n",
    "        if person == '-' and number == '-':\n",
    "            # Try splitting the person_number string\n",
    "            tokens = person_number.split()\n",
    "            for token in tokens:\n",
    "                if token in person_map:\n",
    "                    person = person_map[token]\n",
    "                elif token in number_map:\n",
    "                    number = number_map[token]\n",
    "        # Iterate over the columns to get forms\n",
    "        for col_info in columns_info:\n",
    "            col = col_info['column']\n",
    "            if col == 'person_number':\n",
    "                continue\n",
    "            form = row[col]\n",
    "            if isinstance(form, str) and form.strip() != '':\n",
    "                form = form.strip()\n",
    "                bare_text = strip_accents(form)\n",
    "                bare_base_form = strip_accents(base_word)\n",
    "                mood = col_info.get('mood', '-')\n",
    "                voice = col_info.get('voice', '-')\n",
    "                tense = col_info.get('tense', '-')\n",
    "                # Handle non-finite forms\n",
    "                if person == '-' and number == '-' and 'person_number' in df.columns:\n",
    "                    if 'singular' in person_number:\n",
    "                        number = 's'\n",
    "                    elif 'dual' in person_number:\n",
    "                        number = 'd'\n",
    "                    elif 'plural' in person_number:\n",
    "                        number = 'p'\n",
    "                    else:\n",
    "                        number = '-'\n",
    "                    if 'first' in person_number:\n",
    "                        person = '1'\n",
    "                    elif 'second' in person_number:\n",
    "                        person = '2'\n",
    "                    elif 'third' in person_number:\n",
    "                        person = '3'\n",
    "                    else:\n",
    "                        person = '-'\n",
    "                morph_code = generate_morph_code(\n",
    "                    part_of_speech='v',\n",
    "                    person=person,\n",
    "                    number=number,\n",
    "                    tense=tense,\n",
    "                    mood=mood,\n",
    "                    voice=voice,\n",
    "                    gender='-',\n",
    "                    case='-',\n",
    "                    degree='-'\n",
    "                )\n",
    "                form_entry = {\n",
    "                    'id': sequence_num,\n",
    "                    'text': form,\n",
    "                    'bare_text': bare_text,\n",
    "                    'sequence_num': sequence_num,\n",
    "                    'morph_code': morph_code,\n",
    "                    'base_form': base_word,\n",
    "                    'bare_base_form': bare_base_form,\n",
    "                    'definition': definition\n",
    "                }\n",
    "                forms.append(form_entry)\n",
    "                sequence_num += 1\n",
    "\n",
    "    return forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "    \"\"\"Remove accents from a given string.\"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \"\"\"Clean the DataFrame by removing unwanted characters and standardizing the data.\"\"\"\n",
    "    df = df.dropna(how='all', axis=0)  # Remove empty rows\n",
    "\n",
    "    # Remove unwanted characters and symbols\n",
    "    df = df.replace({'➤': '', '•': '', '\\[': '', '\\]': '', '\\{': '', '\\}': '', '—': ' '}, regex=True)\n",
    "    df = df.replace(r\"\\([^)]*\\)\", \"\", regex=True)  # Remove content within parentheses\n",
    "\n",
    "    # Make all strings lowercase\n",
    "    df = df.map(lambda s: s.lower() if isinstance(s, str) else s)\n",
    "\n",
    "    # Split strings to remove extraneous information\n",
    "    df = df.map(lambda s: s.split(',', 1)[0] if isinstance(s, str) else s)\n",
    "    df = df.map(lambda s: s.split('-', 1)[0] if isinstance(s, str) else s)\n",
    "    df = df.map(lambda s: s.split('+', 1)[0] if isinstance(s, str) else s)\n",
    "    df = df.map(lambda s: s.split('/', 1)[0] if isinstance(s, str) else s)\n",
    "    df = df.map(lambda s: s.split('\\\\', 1)[0] if isinstance(s, str) else s)\n",
    "\n",
    "    df = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    df = df.replace(r\"\\s\\s+\", \" \", regex=True)  # Replace multiple spaces with a single space\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_variations(word, language='ancient greek', show=False, definition_map=None):\n",
    "    # Fetch the Wiktionary page\n",
    "    url = requests.get(f'https://en.wiktionary.org/wiki/{quote(word)}')\n",
    "    soup = bs(url.text, 'html.parser')\n",
    "\n",
    "    # Remove unwanted elements\n",
    "    for tag in soup.find_all('span', {'class': 'tr Latn'}):\n",
    "        tag.decompose()\n",
    "    for tag in soup.find_all('table', {'class': 'audiotable'}):\n",
    "        tag.decompose()\n",
    "    for tag in soup.find_all('sup'):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Find all tables\n",
    "    tables = soup.find_all('table')\n",
    "    gender = None\n",
    "\n",
    "    # DataFrames\n",
    "    dataframes = pd.read_html(str(soup))\n",
    "\n",
    "    # Get the definition of the base word from the definition_map\n",
    "    if definition_map is not None:\n",
    "        normalized_word = strip_accents(word).lower()\n",
    "        definition = definition_map.get(normalized_word, '')\n",
    "    else:\n",
    "        definition = ''\n",
    "        \n",
    "    # Initialize list to collect forms\n",
    "    forms = []\n",
    "    sequence_num = 1  # To keep track of sequence numbers\n",
    "\n",
    "    for i, df in enumerate(dataframes):\n",
    "        # Find the header corresponding to the table\n",
    "        header = tables[i].find_previous('h2').text.replace('[edit]', '').lower().strip()\n",
    "\n",
    "        # Check if the language matches\n",
    "        if header != language:\n",
    "            continue\n",
    "\n",
    "        # Get the part of speech\n",
    "        if tables[i].find_previous('h3'):\n",
    "            part_of_speech = tables[i].find_previous('h3').text.replace('[edit]', '').replace('\\\"', '').lower().strip()\n",
    "        else:\n",
    "            part_of_speech = ''\n",
    "\n",
    "        # Get gender\n",
    "        gender_tag = tables[i].find_previous(class_=\"gender\")\n",
    "        if gender_tag:\n",
    "            gender = gender_tag.find_next(\"abbr\").text.lower()\n",
    "            if 'm' in gender:\n",
    "                gender = 'm'\n",
    "            elif 'f' in gender:\n",
    "                gender = 'f'\n",
    "            elif 'n' in gender:\n",
    "                gender = 'n'\n",
    "            else:\n",
    "                gender = '-'\n",
    "        else:\n",
    "            gender = '-'\n",
    "\n",
    "        # Clean the DataFrame\n",
    "        df = clean_dataframe(df)\n",
    "\n",
    "        # Process based on part of speech\n",
    "        if part_of_speech == 'noun':\n",
    "            forms.extend(parse_noun_table(df, word, gender, sequence_num, definition))\n",
    "            sequence_num += len(df.index)\n",
    "        elif part_of_speech == 'adjective':\n",
    "            forms.extend(parse_adjective_table(df, word, sequence_num, definition))\n",
    "            sequence_num += len(df.index)\n",
    "        elif part_of_speech == 'verb':\n",
    "            forms.extend(parse_verb_table(df, word, sequence_num, definition))\n",
    "            sequence_num += len(df.index)\n",
    "\n",
    "    return pd.DataFrame(forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv_with_wiktionary(csv_path, base_word):\n",
    "    \"\"\"\n",
    "    Update the CSV file with forms from Wiktionary by comparing existing morph codes\n",
    "    and adding any missing forms.\n",
    "    \"\"\"\n",
    "    # Read the original CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Get variations from Wiktionary\n",
    "    scraped_df = generate_variations(base_word)\n",
    "    \n",
    "    if scraped_df.empty:\n",
    "        print(f\"No new forms found for {base_word}.\")\n",
    "        return csv_path  # Return the original path if no updates\n",
    "    \n",
    "    # Ensure morph_code is a string\n",
    "    df['morph_code'] = df['morph_code'].astype(str)\n",
    "    scraped_df['morph_code'] = scraped_df['morph_code'].astype(str)\n",
    "    \n",
    "    # Filter rows corresponding to the base word\n",
    "    base_word_block = df[df['base_form'] == base_word]\n",
    "    existing_morph_codes = set(base_word_block['morph_code'])\n",
    "    \n",
    "    # Get new forms not in the original CSV\n",
    "    new_forms = scraped_df[~scraped_df['morph_code'].isin(existing_morph_codes)]\n",
    "    \n",
    "    if new_forms.empty:\n",
    "        print(f\"All forms of {base_word} are already present in the dataset.\")\n",
    "        return csv_path  # Return the original path if no new forms to add\n",
    "    \n",
    "    # Append new forms to the DataFrame\n",
    "    updated_df = pd.concat([df, new_forms], ignore_index=True)\n",
    "    \n",
    "    # Save the updated DataFrame to a new CSV\n",
    "    updated_csv_path = csv_path.replace('.csv', '_updated.csv')\n",
    "    updated_df.to_csv(updated_csv_path, index=False)\n",
    "    \n",
    "    print(f\"Updated CSV saved to {updated_csv_path}\")\n",
    "    return updated_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing word: ἀάατος\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhopp\\AppData\\Local\\Temp\\ipykernel_21392\\147961841.py:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = pd.read_html(str(soup))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ἀάατος: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "Processing word: ἀαγής\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhopp\\AppData\\Local\\Temp\\ipykernel_21392\\147961841.py:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = pd.read_html(str(soup))\n",
      "C:\\Users\\jhopp\\AppData\\Local\\Temp\\ipykernel_21392\\147961841.py:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = pd.read_html(str(soup))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ἀαγής: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "Processing word: ἄαπτος\n",
      "Error processing ἄαπτος: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "Processing word: ἄατος\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhopp\\AppData\\Local\\Temp\\ipykernel_21392\\147961841.py:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = pd.read_html(str(soup))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ἄατος: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "Processing word: ἀάω\n",
      "Error processing ἀάω: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "All forms have been successfully saved to 'greek_words_with_forms.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhopp\\AppData\\Local\\Temp\\ipykernel_21392\\147961841.py:48: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = pd.read_html(str(soup))\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "greek_words_df = pd.read_csv('greek_words.csv', encoding='utf-8', sep='\\t', index_col=False)\n",
    "\n",
    "# Apply normalization to the base forms\n",
    "greek_words_df['normalized_base_form'] = greek_words_df['base_form'].apply(normalize_word)\n",
    "\n",
    "# Create a mapping from normalized_base_form to definition\n",
    "definition_map = greek_words_df.set_index('normalized_base_form')['definition'].to_dict()\n",
    "\n",
    "# Define desired columns in the correct order\n",
    "desired_columns = ['id', 'text', 'bare_text', 'sequence_num', 'morph_code', 'base_form', 'bare_base_form', 'definition']\n",
    "\n",
    "# Initialize an empty list to collect all forms\n",
    "all_forms = []\n",
    "\n",
    "# Get the list of unique base forms\n",
    "base_forms = greek_words_df['base_form'].unique()\n",
    "# Iterate over each base_form\n",
    "for base_form in base_forms:\n",
    "    print(f\"Processing word: {base_form}\")\n",
    "    try:\n",
    "        # Generate variations\n",
    "        variations_df = generate_variations(base_form, definition_map=definition_map)\n",
    "        \n",
    "        if not variations_df.empty:\n",
    "            # Ensure columns are in the correct order and only include desired columns\n",
    "            variations_df = variations_df[desired_columns]\n",
    "            # Add to all_forms\n",
    "            all_forms.append(variations_df)\n",
    "        else:\n",
    "            print(f\"No variations found for {base_form}. Copying data from greek_words.csv\")\n",
    "            # Get data from greek_words_df where base_form == base_form\n",
    "            word_data = greek_words_df[greek_words_df['base_form'] == base_form]\n",
    "            # Ensure columns are in the correct order and only include desired columns\n",
    "            word_data = word_data[desired_columns]\n",
    "            all_forms.append(word_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {base_form}: {e}\")\n",
    "        # Get data from greek_words_df where base_form == base_form\n",
    "        word_data = greek_words_df[greek_words_df['base_form'] == base_form]\n",
    "        # Ensure columns are in the correct order and only include desired columns\n",
    "        word_data = word_data[desired_columns]\n",
    "        all_forms.append(word_data)\n",
    "\n",
    "# Concatenate all forms into a single DataFrame\n",
    "all_forms_df = pd.concat(all_forms, ignore_index=True)\n",
    "\n",
    "# Reset index to avoid Unnamed columns\n",
    "all_forms_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save to a new CSV file with tab separator\n",
    "all_forms_df.to_csv('greek_words_updated.csv', sep='\\t', index=False, encoding='utf-8')\n",
    "print(\"All forms have been successfully saved to 'greek_words_with_forms.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
