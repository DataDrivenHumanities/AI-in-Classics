{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import unicodedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "    \"\"\"Remove accents from a given string.\"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def generate_morph_code(part_of_speech, person, number, tense, mood, voice, gender, case, degree):\n",
    "    \"\"\"\n",
    "    Generate a morph code based on grammatical features according to the 9-position key.\n",
    "    \"\"\"\n",
    "    morph_code = f\"{part_of_speech}{person}{number}{tense}{mood}{voice}{gender}{case}{degree}\"\n",
    "    return morph_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_noun_table(df, base_word, gender, sequence_num_start):\n",
    "    \"\"\"Parse the noun inflection table and extract forms along with their grammatical features.\"\"\"\n",
    "    # Map for cases and numbers\n",
    "    case_map = {\n",
    "        'nominative': 'n',\n",
    "        'genitive': 'g',\n",
    "        'dative': 'd',\n",
    "        'accusative': 'a',\n",
    "        'vocative': 'v',\n",
    "        'ablative': 'b',\n",
    "        'locative': 'l',\n",
    "        'instrumental': 'i',\n",
    "        'notes:': ''\n",
    "    }\n",
    "    number_map = {\n",
    "        'singular': 's',\n",
    "        'dual': 'd',\n",
    "        'plural': 'p'\n",
    "    }\n",
    "\n",
    "    forms = []\n",
    "    sequence_num = sequence_num_start\n",
    "\n",
    "    # Clean the DataFrame headers\n",
    "    df.columns = [col.lower().strip() for col in df.columns]\n",
    "\n",
    "    # The first column should be cases\n",
    "    cases = df.iloc[:, 0].str.lower().str.strip()\n",
    "    # The rest of the columns are numbers\n",
    "    numbers = [col.lower().strip() for col in df.columns[1:]]\n",
    "\n",
    "    for idx, case in enumerate(cases):\n",
    "        case = case.strip()\n",
    "        case_key = case_map.get(case, '-')\n",
    "        if case_key == '':\n",
    "            continue  # Skip notes or irrelevant rows\n",
    "        for col_idx, num_col in enumerate(numbers):\n",
    "            num_col = num_col.strip()\n",
    "            number_key = number_map.get(num_col, '-')\n",
    "            if number_key == '-':\n",
    "                continue\n",
    "            form = df.iloc[idx, col_idx + 1]\n",
    "            if isinstance(form, str):\n",
    "                form = form.strip()\n",
    "                if form != '':\n",
    "                    bare_text = strip_accents(form)\n",
    "                    bare_base_form = strip_accents(base_word)\n",
    "                    morph_code = generate_morph_code(\n",
    "                        part_of_speech='n',\n",
    "                        person='-',\n",
    "                        number=number_key,\n",
    "                        tense='-',\n",
    "                        mood='-',\n",
    "                        voice='-',\n",
    "                        gender=gender,\n",
    "                        case=case_key,\n",
    "                        degree='-'\n",
    "                    )\n",
    "                    form_entry = {\n",
    "                        'id': sequence_num,\n",
    "                        'text': form,\n",
    "                        'bare_text': bare_text,\n",
    "                        'sequence_num': sequence_num,\n",
    "                        'morph_code': morph_code,\n",
    "                        'base_form': base_word,\n",
    "                        'bare_base_form': bare_base_form,\n",
    "                        'definition': ''  # Add definition if available\n",
    "                    }\n",
    "                    forms.append(form_entry)\n",
    "                    sequence_num += 1\n",
    "    return forms\n",
    "\n",
    "def parse_adjective_table(df, base_word, sequence_num_start):\n",
    "    \"\"\"Placeholder for adjective parsing.\"\"\"\n",
    "    # Implement parsing logic for adjectives\n",
    "    return []\n",
    "\n",
    "def parse_verb_table(df, base_word, sequence_num_start):\n",
    "    \"\"\"Placeholder for verb parsing.\"\"\"\n",
    "    # Implement parsing logic for verbs\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "    \"\"\"Remove accents from a given string.\"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \"\"\"Clean the DataFrame by removing unwanted characters and standardizing the data.\"\"\"\n",
    "    df = df.dropna(how='all', axis=0)  # Remove empty rows\n",
    "\n",
    "    # Remove unwanted characters and symbols\n",
    "    df = df.replace({'➤': '', '•': '', '\\[': '', '\\]': '', '\\{': '', '\\}': '', '—': ' '}, regex=True)\n",
    "    df = df.replace(r\"\\([^)]*\\)\", \"\", regex=True)  # Remove content within parentheses\n",
    "\n",
    "    # Make all strings lowercase\n",
    "    df = df.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
    "\n",
    "    # Split strings to remove extraneous information\n",
    "    df = df.applymap(lambda s: s.split(',', 1)[0] if isinstance(s, str) else s)\n",
    "    df = df.applymap(lambda s: s.split('-', 1)[0] if isinstance(s, str) else s)\n",
    "    df = df.applymap(lambda s: s.split('+', 1)[0] if isinstance(s, str) else s)\n",
    "    df = df.applymap(lambda s: s.split('/', 1)[0] if isinstance(s, str) else s)\n",
    "    df = df.applymap(lambda s: s.split('\\\\', 1)[0] if isinstance(s, str) else s)\n",
    "\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    df = df.replace(r\"\\s\\s+\", \" \", regex=True)  # Replace multiple spaces with a single space\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_variations(word, language='ancient greek', show=False):\n",
    "    # Fetch the Wiktionary page\n",
    "    url = requests.get(f'https://en.wiktionary.org/wiki/{quote(word)}')\n",
    "    soup = bs(url.text, 'html.parser')\n",
    "\n",
    "    # Remove unwanted elements\n",
    "    for tag in soup.find_all('span', {'class': 'tr Latn'}):\n",
    "        tag.decompose()\n",
    "    for tag in soup.find_all('table', {'class': 'audiotable'}):\n",
    "        tag.decompose()\n",
    "    for tag in soup.find_all('sup'):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Find all tables\n",
    "    tables = soup.find_all('table')\n",
    "    part_of_speech_h3 = []\n",
    "    h4 = []  # Inflection/declension\n",
    "    nav = []  # Verb tense, noun declension\n",
    "    gender = None\n",
    "\n",
    "    # DataFrames\n",
    "    dataframes = pd.read_html(str(soup))\n",
    "\n",
    "    # Initialize list to collect forms\n",
    "    forms = []\n",
    "    sequence_num = 1  # To keep track of sequence numbers\n",
    "\n",
    "    for i, df in enumerate(dataframes):\n",
    "        # Find the header corresponding to the table\n",
    "        header = tables[i].find_previous('h2').text.replace('[edit]', '').lower().strip()\n",
    "\n",
    "        # Check if the language matches\n",
    "        if header != language:\n",
    "            continue\n",
    "\n",
    "        # Get the part of speech\n",
    "        if tables[i].find_previous('h3'):\n",
    "            part_of_speech = tables[i].find_previous('h3').text.replace('[edit]', '').replace('\\\"', '').lower().strip()\n",
    "        else:\n",
    "            part_of_speech = ''\n",
    "\n",
    "        # Get gender\n",
    "        gender_tag = tables[i].find_previous(class_=\"gender\")\n",
    "        if gender_tag:\n",
    "            gender = gender_tag.find_next(\"abbr\").text.lower()\n",
    "            if 'm' in gender:\n",
    "                gender = 'm'\n",
    "            elif 'f' in gender:\n",
    "                gender = 'f'\n",
    "            elif 'n' in gender:\n",
    "                gender = 'n'\n",
    "            else:\n",
    "                gender = '-'\n",
    "        else:\n",
    "            gender = '-'\n",
    "\n",
    "        # Clean the DataFrame\n",
    "        df = clean_dataframe(df)\n",
    "\n",
    "        # Process based on part of speech\n",
    "        if part_of_speech == 'noun':\n",
    "            forms.extend(parse_noun_table(df, word, gender, sequence_num))\n",
    "            sequence_num += len(df.index)\n",
    "        elif part_of_speech == 'adjective':\n",
    "            forms.extend(parse_adjective_table(df, word, sequence_num))\n",
    "            sequence_num += len(df.index)\n",
    "        elif part_of_speech == 'verb':\n",
    "            forms.extend(parse_verb_table(df, word, sequence_num))\n",
    "            sequence_num += len(df.index)\n",
    "\n",
    "    return pd.DataFrame(forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv_with_wiktionary(csv_path, base_word):\n",
    "    \"\"\"\n",
    "    Update the CSV file with forms from Wiktionary by comparing existing morph codes\n",
    "    and adding any missing forms.\n",
    "    \"\"\"\n",
    "    # Read the original CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Get variations from Wiktionary\n",
    "    scraped_df = generate_variations(base_word)\n",
    "    \n",
    "    if scraped_df.empty:\n",
    "        print(f\"No new forms found for {base_word}.\")\n",
    "        return csv_path  # Return the original path if no updates\n",
    "    \n",
    "    # Ensure morph_code is a string\n",
    "    df['morph_code'] = df['morph_code'].astype(str)\n",
    "    scraped_df['morph_code'] = scraped_df['morph_code'].astype(str)\n",
    "    \n",
    "    # Filter rows corresponding to the base word\n",
    "    base_word_block = df[df['base_form'] == base_word]\n",
    "    existing_morph_codes = set(base_word_block['morph_code'])\n",
    "    \n",
    "    # Get new forms not in the original CSV\n",
    "    new_forms = scraped_df[~scraped_df['morph_code'].isin(existing_morph_codes)]\n",
    "    \n",
    "    if new_forms.empty:\n",
    "        print(f\"All forms of {base_word} are already present in the dataset.\")\n",
    "        return csv_path  # Return the original path if no new forms to add\n",
    "    \n",
    "    # Append new forms to the DataFrame\n",
    "    updated_df = pd.concat([df, new_forms], ignore_index=True)\n",
    "    \n",
    "    # Save the updated DataFrame to a new CSV\n",
    "    updated_csv_path = csv_path.replace('.csv', '_updated.csv')\n",
    "    updated_df.to_csv(updated_csv_path, index=False)\n",
    "    \n",
    "    print(f\"Updated CSV saved to {updated_csv_path}\")\n",
    "    return updated_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun Variations for λόγος:\n",
      "    id         text    bare_text  sequence_num morph_code base_form  \\\n",
      "0    1      ὁ λόγος      ο λογος             1  n-s---mn-     λόγος   \n",
      "1    2      τὼ λόγω      τω λογω             2  n-d---mn-     λόγος   \n",
      "2    3     οἱ λόγοι     οι λογοι             3  n-p---mn-     λόγος   \n",
      "3    4    τοῦ λόγου    του λογου             4  n-s---mg-     λόγος   \n",
      "4    5  τοῖν λόγοιν  τοιν λογοιν             5  n-d---mg-     λόγος   \n",
      "5    6    τῶν λόγων    των λογων             6  n-p---mg-     λόγος   \n",
      "6    7      τῷ λόγῳ      τω λογω             7  n-s---md-     λόγος   \n",
      "7    8  τοῖν λόγοιν  τοιν λογοιν             8  n-d---md-     λόγος   \n",
      "8    9  τοῖς λόγοις  τοις λογοις             9  n-p---md-     λόγος   \n",
      "9   10    τὸν λόγον    τον λογον            10  n-s---ma-     λόγος   \n",
      "10  11      τὼ λόγω      τω λογω            11  n-d---ma-     λόγος   \n",
      "11  12  τοὺς λόγους  τους λογους            12  n-p---ma-     λόγος   \n",
      "12  13         λόγε         λογε            13  n-s---mv-     λόγος   \n",
      "13  14         λόγω         λογω            14  n-d---mv-     λόγος   \n",
      "14  15        λόγοι        λογοι            15  n-p---mv-     λόγος   \n",
      "\n",
      "   bare_base_form definition  \n",
      "0           λογος             \n",
      "1           λογος             \n",
      "2           λογος             \n",
      "3           λογος             \n",
      "4           λογος             \n",
      "5           λογος             \n",
      "6           λογος             \n",
      "7           λογος             \n",
      "8           λογος             \n",
      "9           λογος             \n",
      "10          λογος             \n",
      "11          λογος             \n",
      "12          λογος             \n",
      "13          λογος             \n",
      "14          λογος             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_3236\\186542921.py:51: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = pd.read_html(str(soup))\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_3236\\186542921.py:15: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.lower() if isinstance(s, str) else s)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_3236\\186542921.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.split(',', 1)[0] if isinstance(s, str) else s)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_3236\\186542921.py:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.split('-', 1)[0] if isinstance(s, str) else s)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_3236\\186542921.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.split('+', 1)[0] if isinstance(s, str) else s)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_3236\\186542921.py:21: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.split('/', 1)[0] if isinstance(s, str) else s)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_3236\\186542921.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.split('\\\\', 1)[0] if isinstance(s, str) else s)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_3236\\186542921.py:24: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# noun test\n",
    "noun_word = 'λόγος'\n",
    "noun_df = generate_variations(noun_word)\n",
    "print(\"Noun Variations for λόγος:\")\n",
    "print(noun_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
