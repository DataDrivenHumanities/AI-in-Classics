{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import unicodedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variations(word,language='ancient greek',show=False):\n",
    "        # CREATES A FOLDER STRUCTURE THAT CONTAINS WORDS ORGANIZED BY PART OF SPEECH\n",
    "        #DECLINES WORDS\n",
    "        #test words\n",
    "        #'Ῥωμαῖος' romans\n",
    "        #'μισώ' hate\n",
    "        #'εἰμί' are to be\n",
    "        #word = word.lower()\n",
    "\n",
    "        #https://en.wiktionary.org/wiki/Ῥωμαῖος\n",
    "        url= requests.get(f'https://en.wiktionary.org/wiki/{quote(word)}')\n",
    "        soup = bs(url.text, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #remove unwanted classes\n",
    "        for tag in soup.find_all('span',{'class':'tr Latn'}):\n",
    "                tag.decompose()\n",
    "        for tag in soup.find_all('table',{'class':'audiotable'}):\n",
    "                tag.decompose()\n",
    "        for tag in soup.find_all('sup'):\n",
    "                tag.decompose()\n",
    "\n",
    "        #HEADERS ---------------------------\n",
    "        #find all tables\n",
    "        tables =soup.find_all('table')\n",
    "        part_of_speech_h3 =[]\n",
    "        h4 =[] # inflection/declension\n",
    "        nav=[] #verb tense, noun first second third delcension\n",
    "        gender =None\n",
    "\n",
    "        #DATAFRAMES----------------------------------\n",
    "\n",
    "        dataframes = pd.read_html(soup.prettify())\n",
    "        for i,df in enumerate(dataframes):\n",
    "                \n",
    "                header = tables[i].find_previous('h2').text.replace('[edit]','').lower().strip()\n",
    "\n",
    "                #GENDER\n",
    "                gender = tables[i].find_previous(class_=\"gender\")\n",
    "                if(gender != None):\n",
    "                        gender = gender.find_next(\"abbr\").text\n",
    "                elif (gender ==None):\n",
    "                        gender = \"n\"\n",
    "\n",
    "\n",
    "                #if(header =='greek'):\n",
    "                        # if modern greek ignore\n",
    "                        #header = ''\n",
    "                #if(header =='ancient greek'):\n",
    "                        #header = 'greek'\n",
    "                if(header != language):\n",
    "                        part_of_speech_h3.append('')\n",
    "                        h4.append('')\n",
    "                        nav.append('')\n",
    "                        continue\n",
    "                if(tables[i].find_previous('h3')):\n",
    "                        part_of_speech_h3.append(tables[i].find_previous('h3').text\n",
    "                        .replace('[edit]','')\n",
    "                        .replace('\\\"','').lower().strip())\n",
    "                else:\n",
    "                        part_of_speech_h3.append('')\n",
    "                if(tables[i].find_previous('h4')):\n",
    "                        h4.append(tables[i].find_previous('h4').text\n",
    "                        .replace('[edit]','')\n",
    "                        .replace('\\\"','').lower().strip())\n",
    "                else:\n",
    "                        h4.append('')\n",
    "                if(tables[i].find_previous('div',{'class':'NavHead'})):\n",
    "                        nav.append(tables[i].find_previous('div',{'class':'NavHead'}).text\n",
    "                        .replace('hide ▲','')\n",
    "                        .replace('\\\"','').replace('/','-').replace(':','-').strip().lower())\n",
    "                        #  : / mess up the file path so you need to remove them\n",
    "                else:\n",
    "                        nav.append('')\n",
    "                ##display(df)\n",
    "                ##CREATE A FOLDER\n",
    "                root_dir = f'{header.replace(\" \", \"_\")}_variations'\n",
    "                os.makedirs(f'{root_dir}/{part_of_speech_h3[i]}/{word.lower()}/',exist_ok=True)\n",
    "                print(f'{root_dir}/{part_of_speech_h3[i]}/{word}/')\n",
    "                ##os.makedirs(nav[i],exist_ok=True)\n",
    "\n",
    "                #print(h3[i])\n",
    "                #print(h4[i])\n",
    "                #print(nav[i])\n",
    "                #print('WRITE TO FILE--------------------------------')\n",
    "\n",
    "                df=dataframes[i]\n",
    "\n",
    "             \n",
    " \n",
    "                # for appending df2 at the end of df1\n",
    "                df.loc[len(df)]= gender\n",
    "                df.iat[-1,0] = \"gender\"\n",
    "\n",
    "                df=df.dropna(how='all',axis=0)\n",
    "\n",
    "\n",
    "\n",
    "                df=df.replace({'➤':''}, regex=True)\n",
    "                df=df.replace({'•':''}, regex=True)\n",
    "                df=df.replace({'\\[':'','\\]':'','\\{':'','\\}':''}, regex=True)\n",
    "                df=df.replace({'—':' '}, regex=True)\n",
    "                #df=df.replace({'/':' ',r'\\\\':' '}, regex=True)\n",
    "                df=df.replace(r\"\\([^)]*\\)\",\"\",regex=True)\n",
    "\n",
    "\n",
    "\n",
    "                # make lowercase\n",
    "                df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "                #df = df.applymap(lambda s:strip_accents_and_lowercase(s) if type(s) == str else s)\n",
    "                df = df.applymap(lambda s: s.split(',', 1)[0] if type(s) == str else s)\n",
    "                df = df.applymap(lambda s: s.split('-', 1)[0] if type(s) == str else s)\n",
    "                df = df.applymap(lambda s: s.split('+', 1)[0] if type(s) == str else s)\n",
    "                df = df.applymap(lambda s: s.split('/', 1)[0] if type(s) == str else s)\n",
    "                df = df.applymap(lambda s: s.split('\\\\', 1)[0] if type(s) == str else s)\n",
    "\n",
    "                df= df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "                df = df.replace(r\"\\s\\s+\",\" \",regex=True)\n",
    "              \n",
    "                # NAN ARE REPALCED BY SPACE CHARACTER\n",
    "                df.to_csv(f'{root_dir}/{part_of_speech_h3[i]}/{word.lower()}/{nav[i]}_{h4[i]}.csv',index=False)\n",
    "\n",
    "                #display(df)\n",
    "                if(show):display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreekWord:\n",
    "    def __init__(self, id, text, bare_text, sequence_num, morph_code, base_form, bare_base_form, definition):\n",
    "        self.id = id\n",
    "        self.text = text\n",
    "        self.bare_text = bare_text\n",
    "        self.sequence_num = sequence_num\n",
    "        self.morph_code = morph_code\n",
    "        self.base_form = base_form\n",
    "        self.bare_base_form = bare_base_form\n",
    "        self.definition = definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_forms(word):\n",
    "    generate_variations(word) #generates the csv table dataframe from wiktionary\n",
    "    #1. read the csv\n",
    "    #2. take in block of all with base word\n",
    "    #3. load all words into custom object, hashmap from morph code to object\n",
    "    #4. scrape the chart, take the chart and figure out what morph codes are missing\n",
    "    #5. generate object with all the words from the missing morph codes\n",
    "    #6. edit csv in place or edit to dataframe to spit into csv\n",
    "    #7. termination function that stores current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv_with_wiktionary(csv_path, base_word):\n",
    "    #1: Read the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    #2: Scrape the chart to obtain all morph codes\n",
    "    all_morph_codes = generate_all_morph_codes(base_word)\n",
    "\n",
    "    #3: Take in block of all words with the base word\n",
    "    base_word_block = df[df['base_form'] == base_word]\n",
    "\n",
    "    #4: Load all words into custom object (hashmap from morph code to object)\n",
    "    greek_word = {}\n",
    "    for index, row in base_word_block.iterrows():\n",
    "        morph_code = row['morph_code']\n",
    "        word = GreekWord(\n",
    "            id=row['id'],\n",
    "            text=row['text'],\n",
    "            bare_text=row['bare_text'],\n",
    "            sequence_num=row['sequence_num'],\n",
    "            morph_code=row['morph_code'],\n",
    "            base_form=row['base_form'],\n",
    "            bare_base_form=row['bare_base_form'],\n",
    "            definition=row['definition']\n",
    "        )\n",
    "        greek_word[morph_code] = word\n",
    "\n",
    "    #5: Determine missing morph codes\n",
    "    missing_morph_codes = []\n",
    "    for morph_code in all_morph_codes:\n",
    "        if morph_code not in greek_word:\n",
    "            missing_morph_codes.append(morph_code)\n",
    "\n",
    "    #6: Generate object with all words from the missing morph codes\n",
    "    missing_words = []\n",
    "    for morph_code in missing_morph_codes:\n",
    "        # Call generate_variations to get word details from Wiktionary\n",
    "        word_details_from_wiktionary = generate_variations(base_word, morph_code)\n",
    "        word = GreekWord(\n",
    "            id=word_details_from_wiktionary['id'],\n",
    "            text=word_details_from_wiktionary['text'],\n",
    "            bare_text=word_details_from_wiktionary['bare_text'],\n",
    "            sequence_num=word_details_from_wiktionary['sequence_num'],\n",
    "            morph_code=morph_code,\n",
    "            base_form=word_details_from_wiktionary['base_form'],\n",
    "            bare_base_form=word_details_from_wiktionary['bare_base_form'],\n",
    "            definition=word_details_from_wiktionary['definition']\n",
    "        )\n",
    "        greek_word[morph_code] = word\n",
    "        missing_words.append(word)\n",
    "\n",
    "    #7: Edit DataFrame to export to CSV\n",
    "    for word in missing_words:\n",
    "        df = df.append(word.__dict__, ignore_index=True)\n",
    "\n",
    "    #8: Termination function that stores current location\n",
    "    updated_csv_path = csv_path.replace('.csv', '_updated.csv')\n",
    "    df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "    return updated_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_morph_codes(word):\n",
    "    #look at dataframe generated chart and figure out what morph codes are missing\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
