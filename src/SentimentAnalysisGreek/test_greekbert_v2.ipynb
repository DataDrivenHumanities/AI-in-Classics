{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ac6444-64f2-445a-8d68-3ff5a1f52446",
   "metadata": {},
   "source": [
    "This is a zero-shot model attempt using a local ancient-greek-text-classification-BERT-2 model, which is a fine-tuned from luvnpce83/ancient-greek-emotion-bert. The model was trained on ancient Greek text, and it is trained to perform 8-class emotion classification on Koine Greek. This model must be trained on your local machine and added to ./greekbert_v1/ancient-greek-text-classification-BERT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bdcdcbc-d95b-42b2-a6eb-13e29e271dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffff74ba-a5a9-4aa9-b735-67b66cf038e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "    \"text-classification\", model=\"rtwins/greekbert_for_text_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a7ac5fb-acf1-49a1-a540-d22914920636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Joy', 'score': 0.9869072437286377}]\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"ἐγώ ὑμᾶς ἐπαινῶ\"\n",
    "result = classifier(sample_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d39837b-7b3c-47c3-80a4-1d8f9b5b9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(df, text_column):\n",
    "    result_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        sequence_to_classify = row[text_column]\n",
    "        result = classifier(\n",
    "            sequence_to_classify\n",
    "        )  # result => list of dictionaries, one dictionary in this case due to csv format\n",
    "        result[0][\"sequence\"] = sequence_to_classify\n",
    "        result_list.append(result[0])\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def predict_sentiment_batch(df, text_column, batch_size):\n",
    "    texts = df[text_column].tolist()\n",
    "    english = df[\"English\"].tolist()\n",
    "    result_list = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        results = classifier(batch)\n",
    "\n",
    "        j = i\n",
    "        for text, r in zip(batch, results):\n",
    "            result_list.append(\n",
    "                {\n",
    "                    \"sequence\": text,\n",
    "                    \"translation\": english[j],\n",
    "                    \"sentiment\": r[\"label\"],\n",
    "                    \"score\": r[\"score\"],\n",
    "                }\n",
    "            )\n",
    "            j += 1\n",
    "\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ce9788-a176-4c1c-96b7-19251a2aeb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label     score                           sequence\n",
      "0        Joy  0.986907                    ἐγώ ὑμᾶς ἐπαινῶ\n",
      "1      Trust  0.997800         ὁ στρατιώτης ἐδωκε χρήματα\n",
      "2      Trust  0.999936               ἐγώ οἶδα τούς Ὅρκους\n",
      "3      Trust  0.999926     ὁ ποιητής τόν στρατιώτην τιμᾷ.\n",
      "4      Anger  0.651851  Οἱ κύνες τούς διώκοντας φεύγουσι.\n",
      "5        Joy  0.999741              ἐγραψα την ἐπιστολήν.\n",
      "6        Joy  0.999965                    Δῶρα ἠγαγόμην. \n",
      "7    Sadness  0.997095             Βίοτος πολλά διδάσκει.\n",
      "8      Trust  0.999907                 ἡ γυνή ἐστί ἀγαθή.\n",
      "9        Joy  0.981954         ὁ ποιητής κάλλιστος ἐστὶν.\n",
      "10       Joy  0.998732          ἡ πόλις γίγνεται πλούσια.\n",
      "11  Surprise  0.999900         το στράτευμα ἐφάνη πάμπολυ\n",
      "12  Surprise  0.812118   μεγάλα τα τόξα τα Περσικά ἐστιν.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./greek_training_data/greek_sentences.csv\", encoding=\"utf8\")\n",
    "result = predict_sentiment(df, \"text\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eabd91-eb4a-4b73-b2ac-67e8f04c2688",
   "metadata": {},
   "source": [
    "On this small sample, high confidence outputs are actually pretty accurate. The biggest outlier is sequence 10 which is labeled sadness despite translating to \"the city becomes rich/prosperous\". There are some other bad labels such as sequence 9, but at least this is low confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08fc4a8d-e803-44f8-bf2c-baf92d0c7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=UserWarning, module=\"torch.utils.data.dataloader\"\n",
    ")\n",
    "dictionary_df = pd.read_csv(\n",
    "    \"../Lemmatizer-GRK/greek_dictionary/nouns.csv\", encoding=\"utf8\", sep=\"\\t\"\n",
    ")\n",
    "results_df = predict_sentiment_batch(dictionary_df, \"FPP\", 16)\n",
    "results_df.to_csv(\"./greekbert_v2_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b22b1-6327-4688-8541-df15b6451dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
