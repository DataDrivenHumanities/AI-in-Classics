{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e071015f-5226-4555-b603-e8559c9eace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075cd1ed-1796-49fc-b315-1bb743fa2e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d1fe525f11494d916c6bae118d4ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wills\\dev\\Trojan-Parse-Project\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wills\\.cache\\huggingface\\hub\\models--MoritzLaurer--DeBERTa-v3-base-mnli-fever-anli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e640e1c4718b4272bfd3502d7a0ac223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4a37e0199342d99107e76f7a1176eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a7eaa18fa14aea81ac6cc4d307a076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c721081ff54db0a57e96191efb4eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5884f2ae75144e7cbae329695a9eed46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c828025ecc4cad92ea84cce93aa55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431a0406-3b02-4583-8987-3a7580f35c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./greek_training_data/greek_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bea56aa7-b4ad-4947-b199-3e661b09eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"trust\"]\n",
    "sample_text = \"ἐγώ ὑμᾶς ἐπαινῶ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212db316-68a6-46d4-b2cb-2a231350a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'ἐγώ ὑμᾶς ἐπαινῶ',\n",
       " 'labels': ['anticipation',\n",
       "  'trust',\n",
       "  'joy',\n",
       "  'surprise',\n",
       "  'fear',\n",
       "  'anger',\n",
       "  'sadness',\n",
       "  'disgust'],\n",
       " 'scores': [0.515584409236908,\n",
       "  0.16567815840244293,\n",
       "  0.08153747767210007,\n",
       "  0.0718863382935524,\n",
       "  0.046777334064245224,\n",
       "  0.04591739550232887,\n",
       "  0.044985320419073105,\n",
       "  0.02763357199728489]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the model against the sample text\n",
    "# model score outputs indicate a confidence rating that the model has applied to the sample text\n",
    "classifier(sample_text, text_labels, multi_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b9ad3d-e868-407a-a610-b4cd46682582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction on entire given corpus.\n",
    "# text_column is the column of the dataframe that holds the text in question\n",
    "# text_labels is the emotional labels that should be addressed\n",
    "\n",
    "def predict_sentiment(df, text_column, text_labels):\n",
    "    result_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        sequence_to_classify = row[text_column]\n",
    "        result = classifier(sequence_to_classify, text_labels, multi_label = False)\n",
    "        result['sentiment'] = result['labels'][0]\n",
    "        result['score'] = result['scores'][0]\n",
    "        result_list.append(result)\n",
    "    result_df = pd.DataFrame(result_list)[['sequence','sentiment', 'score']]\n",
    "    result_df = pd.merge(df, result_df, left_on = \"text\", right_on=\"sequence\", how = \"left\")\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3098c43-9495-4b6f-9b95-12341e98b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = predict_sentiment(df, \"text\", text_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dd57cbe-acf7-475e-95e7-1d85faf669b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 text                           sequence  \\\n",
      "0                     ἐγώ ὑμᾶς ἐπαινῶ                    ἐγώ ὑμᾶς ἐπαινῶ   \n",
      "1          ὁ στρατιώτης ἐδωκε χρήματα         ὁ στρατιώτης ἐδωκε χρήματα   \n",
      "2                ἐγώ οἶδα τούς Ὅρκους               ἐγώ οἶδα τούς Ὅρκους   \n",
      "3      ὁ ποιητής τόν στρατιώτην τιμᾷ.     ὁ ποιητής τόν στρατιώτην τιμᾷ.   \n",
      "4   Οἱ κύνες τούς διώκοντας φεύγουσι.  Οἱ κύνες τούς διώκοντας φεύγουσι.   \n",
      "5               ἐγραψα την ἐπιστολήν.              ἐγραψα την ἐπιστολήν.   \n",
      "6                     Δῶρα ἠγαγόμην.                     Δῶρα ἠγαγόμην.    \n",
      "7              Βίοτος πολλά διδάσκει.             Βίοτος πολλά διδάσκει.   \n",
      "8                  ἡ γυνή ἐστί ἀγαθή.                 ἡ γυνή ἐστί ἀγαθή.   \n",
      "9          ὁ ποιητής κάλλιστος ἐστὶν.         ὁ ποιητής κάλλιστος ἐστὶν.   \n",
      "10          ἡ πόλις γίγνεται πλούσια.          ἡ πόλις γίγνεται πλούσια.   \n",
      "11         το στράτευμα ἐφάνη πάμπολυ         το στράτευμα ἐφάνη πάμπολυ   \n",
      "12   μεγάλα τα τόξα τα Περσικά ἐστιν.   μεγάλα τα τόξα τα Περσικά ἐστιν.   \n",
      "\n",
      "       sentiment     score  \n",
      "0   anticipation  0.515584  \n",
      "1   anticipation  0.254794  \n",
      "2        sadness  0.225709  \n",
      "3          trust  0.309171  \n",
      "4   anticipation  0.696122  \n",
      "5   anticipation  0.374222  \n",
      "6        sadness  0.298548  \n",
      "7   anticipation  0.606329  \n",
      "8   anticipation  0.299297  \n",
      "9   anticipation  0.505696  \n",
      "10  anticipation  0.547435  \n",
      "11           joy  0.449575  \n",
      "12  anticipation  0.310212  \n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe120e15-7ef2-4d28-bfe1-34d260397b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv2)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
