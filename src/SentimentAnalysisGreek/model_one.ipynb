{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d7e6308-0ac6-4832-a615-f9c75ec2296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForTokenClassification, BertTokenizerFast, TrainingArguments, Trainer, DataCollatorForTokenClassification, AutoTokenizer\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import os\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a355f5fa-d502-4e7c-8ad9-a7817b593b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"transformers_version\": \"4.56.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = DistilBertConfig()\n",
    "sub_directory = \"config_one\"\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05c89a30-090d-4556-ba90-f68061023e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.save_pretrained(save_directory=f\"./greek_configs/{sub_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3f14168-774f-4fa2-8944-548e4de5fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DistilBertConfig.from_pretrained(f\"./greek_configs/{sub_directory}/config.json\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "model = DistilBertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9061fb-bbb3-49a6-a971-2947a383984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repackage training data for model \n",
    "# hard coded to find negative, neutral, positive folders within greek_training_data directory\n",
    "def pre_process_training_data():\n",
    "    # go into each directory in greek_training_data\n",
    "    # extract each line from a csv into a new dataframe with the sentiment next to it\n",
    "    # return dataframe\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7207726-52dc-4a19-b00f-ec716bd2f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the tokenizer\n",
    "tokenizer_trainer = ByteLevelBPETokenizer()\n",
    "tokenizer_trainer.train(files=[corpus_file], vocab_size=8000, min_frequency=2, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
    "tokenizer_trainer.save_model(\"tokenizer_out\")\n",
    "\n",
    "#load tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"tokenizer_out\", unk_token=\"<unk>\", pad_token=\"<pad>\", cls_token=\"<s>\", sep_token=\"</s>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv2)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
