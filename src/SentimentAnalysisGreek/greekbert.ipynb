{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1353e9a3-c961-490e-8b73-d9bcc188f748",
   "metadata": {},
   "source": [
    "This is a zero-shot model attempt using pranaydeeps/Ancient-Greek-BERT. The model was trained on ancient Greek text, but it is not capable of performing zero-shot classification and thus fails to be performant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c818b-33db-4594-8232-bf664b961903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "075cd1ed-1796-49fc-b315-1bb743fa2e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"pranaydeeps/Ancient-Greek-BERT\")\n",
    "model = AutoModel.from_pretrained(\"pranaydeeps/Ancient-Greek-BERT\")  \n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\", model=model, tokenizer=tokenizer, device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "431a0406-3b02-4583-8987-3a7580f35c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        FPP                        English  Sentiment\n",
      "0           0  αβδηριτης                a man of Abdera        NaN\n",
      "1           1  αβελτερια  silliness, stupidity, fatuity        NaN\n",
      "2           2      αβιοι     without a living, starving        NaN\n",
      "3           3    αβλαβια              freedom from harm        NaN\n",
      "4           4      αβλης                     not thrown        NaN\n",
      "Index(['Unnamed: 0', 'FPP', 'English', 'Sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Lemmatizer-GRK/greek_dictionary/nouns.csv\", encoding=\"utf8\", sep=\"\\t\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bea56aa7-b4ad-4947-b199-3e661b09eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = [\n",
    "    \"anger\",\n",
    "    \"anticipation\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"joy\",\n",
    "    \"sadness\",\n",
    "    \"surprise\",\n",
    "    \"trust\",\n",
    "]\n",
    "sample_text = \"ἐγώ ὑμᾶς ἐπαινῶ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "212db316-68a6-46d4-b2cb-2a231350a64f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# run the model against the sample text\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model score outputs indicate a confidence rating that the model has applied to the sample text\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\dev\\Trojan-Parse-Project\\venv\\lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:209\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[1;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\dev\\Trojan-Parse-Project\\venv\\lib\\site-packages\\transformers\\pipelines\\base.py:1459\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32m~\\dev\\Trojan-Parse-Project\\venv\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:127\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    126\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m--> 127\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\dev\\Trojan-Parse-Project\\venv\\lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:246\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.postprocess\u001b[1;34m(self, model_outputs, multi_label)\u001b[0m\n\u001b[0;32m    244\u001b[0m sequences \u001b[38;5;241m=\u001b[39m [outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m outputs \u001b[38;5;129;01min\u001b[39;00m model_outputs]\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 246\u001b[0m     logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m model_outputs])\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m model_outputs])\n",
      "File \u001b[1;32m~\\dev\\Trojan-Parse-Project\\venv\\lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:246\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    244\u001b[0m sequences \u001b[38;5;241m=\u001b[39m [outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m outputs \u001b[38;5;129;01min\u001b[39;00m model_outputs]\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 246\u001b[0m     logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m model_outputs])\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m model_outputs])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'logits'"
     ]
    }
   ],
   "source": [
    "# run the model against the sample text\n",
    "# model score outputs indicate a confidence rating that the model has applied to the sample text\n",
    "classifier(sample_text, text_labels, multi_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b9ad3d-e868-407a-a610-b4cd46682582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction on entire given corpus.\n",
    "# text_column is the column of the dataframe that holds the text in question\n",
    "# text_labels is the emotional labels that should be addressed\n",
    "\n",
    "\n",
    "def predict_sentiment(df, text_column, text_labels):\n",
    "    result_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        sequence_to_classify = row[text_column]\n",
    "        result = classifier(sequence_to_classify, text_labels, multi_label=False)\n",
    "        result[\"sentiment\"] = result[\"labels\"][0]\n",
    "        result[\"score\"] = result[\"scores\"][0]\n",
    "        result_list.append(result)\n",
    "    result_df = pd.DataFrame(result_list)[[\"sequence\", \"sentiment\", \"score\"]]\n",
    "    result_df = pd.merge(df, result_df, left_on=\"text\", right_on=\"sequence\", how=\"left\")\n",
    "    return result_df\n",
    "\n",
    "def predict_sentiment_batch(df, text_column, text_labels, batch_size):\n",
    "    texts = df[text_column].tolist()\n",
    "    result_list = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        results = classifier(batch, text_labels, multi_label=False)\n",
    "        \n",
    "        for text, r in zip(batch, results):\n",
    "            result_list.append({\n",
    "                \"sequence\": text,\n",
    "                \"sentiment\": r[\"labels\"][0],\n",
    "                \"score\": r[\"scores\"][0],\n",
    "            })\n",
    "    \n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    return df.merge(result_df, left_on=text_column, right_on=\"sequence\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3098c43-9495-4b6f-9b95-12341e98b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.utils.data.dataloader\")\n",
    "\n",
    "results_df = predict_sentiment_batch(df, \"FPP\", text_labels, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dd57cbe-acf7-475e-95e7-1d85faf669b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0        FPP                         English  Sentiment  \\\n",
      "0               0  αβδηριτης                 a man of Abdera        NaN   \n",
      "1               1  αβελτερια   silliness, stupidity, fatuity        NaN   \n",
      "2               2      αβιοι      without a living, starving        NaN   \n",
      "3               3    αβλαβια               freedom from harm        NaN   \n",
      "4               4      αβλης                      not thrown        NaN   \n",
      "...           ...        ...                             ...        ...   \n",
      "13003       12585     ωφελιη  help, aid, succour, assistance        NaN   \n",
      "13004       12586     ωφελημ                        a useful        NaN   \n",
      "13005       12587   ωφελησις              a helping, aiding;        NaN   \n",
      "13006       12588      ωχρος               paleness, wanness        NaN   \n",
      "13007       12589    ωχροτης                        paleness        NaN   \n",
      "\n",
      "        sequence     sentiment     score  \n",
      "0      αβδηριτης         anger  0.137011  \n",
      "1      αβελτερια         trust  0.135825  \n",
      "2          αβιοι         trust  0.129486  \n",
      "3        αβλαβια         anger  0.132995  \n",
      "4          αβλης          fear  0.129369  \n",
      "...          ...           ...       ...  \n",
      "13003     ωφελιη         trust  0.139870  \n",
      "13004     ωφελημ  anticipation  0.132134  \n",
      "13005   ωφελησις      surprise  0.134815  \n",
      "13006      ωχρος           joy  0.140927  \n",
      "13007    ωχροτης  anticipation  0.137663  \n",
      "\n",
      "[13008 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe120e15-7ef2-4d28-bfe1-34d260397b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"./greekBert_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedf0c8-ee29-4118-a5b6-4d6e36c27d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv2)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
